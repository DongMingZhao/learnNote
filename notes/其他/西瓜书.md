> 前言：此笔记==仅用于扫盲==，详细推导过程请看《西瓜书》

# 第二章：模型评估与选择

## 1、经验误差与过拟合

- **误差**：学习器的实际预测输出与样本的真实输出之间的差异
  - **训练误差或经验误差**：学习器在训练集上的误差
  - **泛化误差**：在新样本上的误差
- **过拟合**：对训练样本所包含的不太一般的特性都学到了，而导致泛化性能下降
- **欠拟合**：对训练样本的一般性质未学习好

## 2、评估方法

- **模型选择**：对候选模型的泛化误差进行评估，然后选择泛化误差最小的模型

- 评估方法：通过实验测试来对学习器的泛化误差进行评估并作出选择

  > - 测试集：用来测试学习器对新样本的判别能力
  > - 测试误差：作为泛化误差的近似

  - **留出法**：直接将数据 D 划分为两个互斥的集合，即：训练集 S 和测试集 T

    > - **注意**：测试集的划分要保证数据分布的一致性，避免因数据划分过程引入额外的偏差
    > - **分层采样**：保留类别比例的采样方式
    >
    > 建议：将大约 2/3 ~ 4/5 的样本用于训练，剩余样本用于测试，且测试集至少30个样例

  - **交叉验证法(k 折交叉验证)**：先将数据集 D 划分为 k 个大小相似的互斥子集，然后每次用 k-1 个子集的并集作为训练集，余下的那个子集作为测试集

    > - 各子集的数据采用“分层采样”划分
    >
    > ![](../pics/machine/machine_1.png)

  - **留一法**：使用的训练集与初始数据集相比只少了一个样本

    > - 优点：预估结果更准确，且**不受随机样本划分方式的影响**
    > - 缺点：数据集较大时，计算开销过大

  - **自助法**：以自助采样法为基础，从数据集 D 中采样产生数据集 $D^{'}$ 

    - 每次随机从 D 中挑选一个样本，将其**拷贝**放入 $D{'}$ 

      > 该样本下次采样时，仍可能被采样到

    - 该过程重复 m 次后，便得到 $D^{'}$ 

      > - m 次采样中，始终**不被采到**的概率是 $(1 - \frac{1}{m})^m$，即 $\lim_{m \rightarrow +\infty} (1 - \frac{1}{m}^m) \Rightarrow \frac{1}{e} \approx 0.368$ 
      > - 将 $D^{'}$ 用作训练集，$D / D^{'}$ 用作测试集

    > - 优点：
    >   - 在数据集较小，难以有效划分训练/测试集时有用
    >   - 避免因训练规模不同而导致的估计偏差
    > - 缺点：自助法产生的数据集改变了初始数据集的分布，会引入估计偏差

## 3、性能度量

>  **性能度量**：衡量模型泛化能力的评价标准

- **错误率**：分类错误的样本数占样本总数的比例

  > - 均方误差： $E(f;D) = \frac{1}{m}\sum^m_{i=1}I(f(x_i) \neq y_i)$ 
  > - 加权误差： $E(f;D) = \int_{x \rightarrow D} I(f(x) = y)p(x)dx$  

- **精度**：分类正确的样本数占样本总数的比例，

  > - 均方误差： $acc(f;D) = \frac{1}{m}\sum^m_{i=1}I(f(x_i) = y_i) = 1 - E(f;D)$ 
  > - 加权误差： $acc(f;D) = \int_{x \rightarrow D} I(f(x) = y) p(x) dx = 1 - E(f;D)$ 

- 查准率与查全率：

  > 查准率与查全率是一对矛盾变量：查准率高时，查全率低；查全率高时，查准率低
  >
  > ![](../pics/machine/machine_2.png)

  - **查准率**： 即**准确率**，$P = \frac{TP}{TP + FP}$
  - **查全率**： 即**召回率**，$R = \frac{TP}{TP + FN}$

- **P-R 曲线**：直观的显示出学习器在样本总体上的查全率与查准率

  > ![](../pics/machine/machine_3.png)
  >
  > - **P-R 曲线下面积大小**：在一定程度上表征了学习器在查准率与查全率上取得相对“双高”的比例
  >
  > - 平衡点(BEP)：是“查准率 = 查全率”时的取值、
  >
  > - **F1 度量**：$F1 = \frac{2 * P * R}{P + R} = \frac{2 * TP}{样例总数 + TP - TN}$ 
  >
  > - **$F_{\beta}$ 度量**：$F_{\beta} = \frac{(1 + \beta ^2) * P * R}{(\beta ^2 * P) + R}$ 
  >
  >   > $\beta > 0$ 度量了查全率对查准率的相对重要性：
  >   >
  >   > - $\beta = 1$ 时，退化为标准的 F1
  >   > - $\beta > 1$ 时，查全率有更大影响
  >   > - $\beta < 1$ 时，查准率有更大影响

- **n 个样例上考察查准率与查全率**：

  - 法一： 先分别计算，再计算平均值

    > - 宏查准率： $macro-P = \frac1n \sum^n_{i=1} P_i$
    > - 宏查全率： $macro-R = \frac1n \sum^n_{i=1} R_i$
    > - 宏 F1： $macro-F1 = \frac{2 \times macroP \times macroR}{macroP + macroR}$

  - 法二： 先平均，再对平均值计算

    > - 微查准率： $micro-P = \frac{\overline{TP}}{\overline{TP} + \overline{FP}}$ 
    > - 微查全率： $micro-R = \frac{\overline{TP}}{\overline{TP} + \overline{FN}}$ 
    >
    > - 微 F1： $micro-F1 = \frac{2 \times microP \times microR}{microP + microR}$ 

- **ROC(受试者工作特征)曲线**： 根据学习器的预测结果**对样例进行排序**，**按此顺序逐个把样本作为正例进行预测**，每次计算出两个重要量的值，并以它们为横纵坐标，构造 ROC 曲线

  > - **纵轴：真正例率** $TPR = \frac{TP}{TP + FN}$
  > - **横轴：假正例率** $FPR = \frac{FP}{TN + FP}$

- **AUC(ROC 曲线下面积)**：通过对 ROC 曲线下各部分的面积求和而得 

  > - 公式： $AUC = \frac12 \sum^{m-1}_{i=1} (x_{i+1} - x_i) * (y_i + y_{i+1})$ 
  >
  > - 注意：AUC 考虑的是样本预测的排序质量，因此与排序误差有紧密联系
  >
  > - **排序损失**：$l_{rank} = \frac{1}{m^+ m^-} \sum_{x^+ \in D^+} \sum_{x^- \in D^-} (I(f(x^+) < f(x^-)) + \frac12 I(f(x^+) = f(x^-)))$ 
  >
  >   > - $AUC = 1 - l_{rank}$ 

- **非均等代价**：

  - **代价敏感错误率**： $E(f;D;cost) = \frac1m (\sum_{x_i \in D^+} I(f(x_i) \neq y_i) \times cost_{01} + \sum_{x_i \in D^-} I(f(x_i) \neq y_i) \times cost_{10})$ 

    > 若令  $cost_{ij}$ 中的 i、j 取值不限于 0、1，则可定义出多分类任务的代价敏感性能度量

  - **代价曲线**： 可在非均等代价下，反应出学习器的期望总体代价

    > - 横轴： 取值为 [0,1] 的正例概率代价 $P(+)cost = \frac{p \times cost_{01}}{p \times cost_{01} + (1 - p) \times cost_{10}}$，$p$ 为样例为正例的概率
    > - 纵轴： 取值为 [0,1] 的归一化代价 $cost_{norm} = \frac{FNR \times p \times cost_{01} + FPR \times (1 - p) \times cost_{10}}{p \times cost_{01} + (1 - p) \times cost_{10}}$，FNR 与 FPR 源于 ROC
    >
    > 绘制： ROC 曲线上每一点对应了代价平面上的一条线段

## 4、比较校验

- **假设检验**： 是对学习器泛化错误率分布的某种判断或猜想

  > 泛化错误率为 $\epsilon$ 的学习器被测得**测试错误率为 $\hat{\epsilon}$** 的概率： $P(\hat{\epsilon};\epsilon) = \begin{pmatrix}m \\ \hat{\epsilon} \times m\end{pmatrix} \epsilon^{\hat{\epsilon} \times m} (1 - \epsilon)^{m - \hat{\epsilon} \times m}$  
  >
  > - 令 $\alpha P(\hat{\epsilon};\epsilon) / \alpha \epsilon = 0$ 知，当 $\epsilon = \hat{\epsilon}$ 时，$P(\hat{\epsilon};\epsilon)$ 最大；$|\epsilon - \hat{\epsilon}|$ 增大时，$P(\hat{\epsilon};\epsilon)$ 减小

- **交叉验证 t 校验**： 对 **k 折交叉验证**产生的 k 对测试错误率，先对没对结果求差 $\bigtriangleup_i = \epsilon^A_i - \epsilon^B_i$，根据差值 $\bigtriangleup_i$ 来对“学习器 A 与 B 性能相同“这个假设做 t 校验，计算出差值的均值 $\mu$ 和方差 $\sigma^2$

  > 在显著度 $\alpha$ 下：$t_{\alpha/2,k-1}$ 是自由度为 $k-1$ 的 $t$ 分布上尾部积累分布为 $\frac{\alpha}{2}$ 的临界值
  >
  > - 若变量 $\tau_t = |\frac{\sqrt{k}\mu}{\sigma}|$ 小于临界值 $t_{\alpha/2,k-1}$，则假设不能拒绝
  >
  >   > 即认为两个学习器的性能没有显著差别
  >
  > - 否则，可认为两个学习器的性能有显著差别，且平均错误率小的学习器性能较优
  >
  > 前提： 测试错误率均为泛化错误率的独立采样
  >
  > 局限： 使用交叉验证等实验估计方法时，不同轮次的训练集会有一定程度的重叠，导致过高估计假设成立的概率
  >
  > 缓解方法： 采用”**5 X 2 交叉验证**“法，即做 5 次 2 折交叉验证
  >
  > - 在每次 2 折交叉验证之前随机将数据打乱，使得 5 次交叉验证中的数据划分不重复
  > - 对学习器 A 和 B，第 i 次 2 折交叉验证将产生两对测试错误率，对它们分别求差，得到第 1 折上的差值 $\triangle^1_i$ 和第 2 折上的差值 $\triangle^2_i$ 

- **McNemar 校验**： 对于二分类问题与留出法

- **Friedman 校验**：

- **Nemenyi 校验**： 

## 5、偏差与方差

> 测试样本 $x$，$y_D$ 为 $x$ 在数据集的标记，$y$ 为 $x$ 真实标记，$f(x;D)$ 为训练集 D 上学得模型 f 在 x 的预测输出

以回归任务为例：

- 学习算法的期望预测： $\overline{f}(x) = E_D[f(x;D)]$ 
- 相同样本的不同训练集产生的方差： $var(x) = E_D[(f(x;D) - \overline{f}(x))^2]$ 
- 噪声： $\varepsilon^2 = E_D[(y_D - y)^2]$ 
- 期望输出与真实标记的差别，即偏差： $bias^2(x) = (\overline{f}(x) - y)^2$ 

> $E(f;D) = bias^2(x) + var(x) + \varepsilon^2$，即泛化误差为偏差、方差、噪声之和

# 第三章：线性模型

## 1、基本形式

- 线性形式： $f(x) = w_1x_1 + w_2x_2 + ... + w_dx_d + b$ 

  > $w = \frac{\sum^m_{i=1} y_i(x_i - \overline{x})}{\sum^m_{i=1}x^2_i - \frac{1}{m}(\sum^m_{i=1}x_i)^2}$，$\overline{x} = \frac1m \sum^m_{i=1}x_i$ 为 x 的均值
  >
  > $b = \frac1m \sum^m_{i=1}(y_i - wx_i)$ 

- 向量形式： $f(x) = w^Tx + b$ 

## 2、线性回归

- **最小二乘法**： 试图找到一条直线，使所有样本到直线上的欧式距离之和最小

- 多元线性回归： $f(x_i) = w^Tx_i + b$，使得 $f(x_i) \approx y_i$ 

- 多元线性回归向量模型： $f(\hat{x_i}) = \hat{x_i}^T (X^TX)^{-1}X^Ty$ 

  > ![](D:/architect_learn/learnNote/pics/machine/machine_5.png)

## 3、对数几率回归

- **对数几率函数**： $y = \frac{1}{1 + e^{-z}}$ 

  > ![](D:/architect_learn/learnNote/pics/machine/machine_6.png)

- **对数几率**： $logit = ln \frac{y}{1 - y}$ 

## 4、线性判别分析

- **线性判别分析(LDA)**：给定训练样例投影到一条直线上，使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离

  > 在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别
  >
  > - 同类投影点尽可能近，即 $w^T\sum_0w + w^T\sum_1w$ **尽可能小** 
  >
  > - 异类投影点尽可能远，即 $||w^T\mu_0 - w^T\mu_1||_2^2$ **尽可能大** 
  >
  >   > $w$ 表示直线，$\mu_i, \sum_i$ 表示第 $i \in \{0,1\}$ 类示例的**均值向量**和**协方差矩阵** 
  >
  > **最大化目标**： $J = \frac{||w^T\mu_0 - w^T\mu_1||_2^2}{w^T\sum_0w + w^T\sum_1w} = \frac{w^T(\mu_0 - \mu_1)(\mu_0 - \mu_1)^Tw}{w^T(\sum_0 + \sum_1)w} = \frac{w^TS_bw}{w^TS_ww}$ 
  >
  > - 类内散度矩阵： $S_w = \sum_0 + \sum_1 = \sum_{x \in X_0}(x - \mu_0)(x - \mu_0)^T + \sum_{x \in X_1}(x - \mu_1)(x - \mu_1)^T$ 
  > - 类间散度矩阵： $S_b = (\mu_0 - \mu_1)(\mu_0 - \mu_1)^T$ 
  >
  > ![](D:/architect_learn/learnNote/pics/machine/machine_7.png)

## 5、多分类学习

- **多分类学习**：将多分类任务**拆解**为若干个二分类任务，然后为每个二分类任务训练分类器

  > 经典的拆分策略：一对一(OvO)、一对其余(OvR)、多对多(MvM)

  - OvO：将 N 个类别两两配对，从而产生 N(N - 1)/2 个二分类任务

  - OvR： 每次将一个类的样例做为正例、其他样例作为反例来训练 N 个分类器

  - MvM： 每次将若干个类做为正类，若干个其他类作为反类

    > MvM 的正、反类构造必须有特殊的设计，不能随意选取
    >
    > - 常用技术：**纠错输出码(ECOC)**，即将编码的思想引入类别拆分，并尽可能在解码过程中具有容错性，工作过程分为两步：
    >   - 编码： 对 N 个类别做 M 次划分，每次划分将一部分类别化为正类，一部分化为反类，从而形成一个二分类训练集，这样可产生 M 个分类器
    >   - 解码： M 个分类器分别对测试样本进行预测，这些预测标记组成一个编码，将这个预编码与每个类各自的编码进行比较，返回其中距离最小的类别作为最终预测结果

- **编码矩阵**： **实现类别划分**，常见形式：

  - 二元码：将每个类别分别指定为正类和反类 

  - 三元码： 在正、反类之外，还可指定“停用类”

    ![](../pics/machine/machine_8.png)

## 6、类别不平衡问题

- **类别不平衡**： 指分类任务中，不同类别的训练样例数目差别很大

- **再缩放**： 类别不平衡的基本策略，即令 $\frac{y'}{1 - y'} = \frac{y}{1 - y} \times \frac{m^-}{m^+}$ 

  > - 分类器决策规则： 若 $\frac{y}{1 - y} > 1$，则预测为正例
  >
  > - 训练集正、反例数目不同时：若 $\frac{y}{1 - y} > \frac{m^+}{m^-}$，则预测为正例
  >
  >   > $m^+$ 表示正例数目，$m^-$ 表示反例数目
  >
  > 实现“训练集样本是总体的无偏采样”的现有技术： 
  >
  > - 第一类： 直接对训练集里的反类样例进行“欠采样”
  >
  >   > 欠采样： 随机丢弃反例
  >   >
  >   > EasyEnsemble： 利用集成学习机制，将反例划分为若干个集合，供不同学习器使用
  >   >
  >   > - 既使每个学习器都进行了欠采样，又在全局来看，不会丢失重要信息
  >
  > - 第二类： 对训练集里的正类样例进行“过采样”
  >
  >   > 过采样： 增加很多正例
  >   >
  >   > SMOTE 算法： 通过对训练集里的正例进行插值来产生额外的正例，防止过拟合的出现
  >
  > - 第三类： 直接基于原始训练集进行学习，但在用训练好的分类器进行预测时，将 $\frac{y'}{1 - y'} = \frac{y}{1 - y} \times \frac{m^-}{m^+}$ 嵌入到其决策过程中

# 第四章：决策树

## 1、基本流程

- 决策树： 基于树结构来进行决策，是一个递归过程

  ![](../pics/machine/machine_9.png)

- **决策树递归**情形：

  - 第一种： 当前结点包含的样本全属于同一类别，**无需划分**
  - 第二种： 当前属性集为空，或所有样本在所有属性上取值相同，**无法划分**
  - 第三种： 当前结点包含的样本集合为空，**不能划分**

  ![](../pics/machine/machine_10.png)

## 2、划分选择

**度量样本集合纯度**的指标

- **信息熵**： $Ent(D) = -\sum^{|y|}_{k=1}p_k log_2p_k$ 

  > $Ent(D)$ 值越小，则 D 的纯度越高

- **信息增益**： $Gain(D,a) = Ent(D) - \sum^V_{v=1}\frac{|D^v|}{|D|}Ent(D^v)$ 

  > 信息增益越大，则使用属性 $a$ 来进行划分所获得的纯度提升越大

- **增益率**： $Gain_ratio(D,a) = \frac{Gain(D,a)}{IV(a)}$，其中 $IV(a) = -\sum^V_{v=1}\frac{|D^v|}{|D|}log_2\frac{|D^v|}{|D|}$ 称为属性 $a$ 的固有值

  > 属性 $a$ 的可能取值数目越多(即 V 越大)，则 $IV(a)$ 的值通常会越大

- **基尼值**： $Gini(D) = \sum^{|y|}_{k=1}\sum_{k' \neq k} p_kp_{k'} = 1 - \sum^{|y|}_{k=1}p^2_k$ 

  > $Gini(D)$ 反映了从数据集 D 中随机抽取两个样本，其类别标记不一致的概率
  >
  > - $Gini(D)$ 越小，则数据集 D 的纯度越高

- **基尼指数**： $Gini\_index(D,a) = \sum^V_{v=1}\frac{|D^v|}{|D|}Gini(D^v)$ 

  > 基尼指数越小，划分属性越优

## 3、剪枝处理

- **剪枝**： 是决策树学习算法对付“过拟合”的重要手段
  - **预剪枝**： 指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点
  - **后剪枝**： 先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶节点能带来决策树泛化性能提升，则将该子树替换为叶结点

## 4、连续与缺失值

- **连续值处理**： 采用二分法对连续属性进行处理
- **缺失值处理**： 

## 5、多变量决策树





# 第五章：神经网络

## 1、神经元模型

- 神经网络： 由具有适应性的简单单元组成的广泛并进行互连的网络，能模拟生物神经系统对真实世界物体所作出的交互反应

- **神经元模型**： 神经网络的最基本成分

  ![](../pics/machine/machine_11.png)

- **激活函数**： 处理输入，并产生输出

  - 阶跃函数： 
  - Sigmoid 函数： 

  ![](../pics/machine/machine_12.png)

## 2、感知机与多层网络

- **感知机**： 由两层神经元组成，输入层接收外界输入信号后传递给输出层，输出层是 M-P 神经元

  > 感知机能实现逻辑与、或、非运算
  >
  > ![](../pics/machine/machine_13.png)
  >
  > - 感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元

- **多层前馈神经网络**： 输入层与输出层之间含有隐含层，隐含层和输出层神经元都拥有激活函数

  > ![](../pics/machine/machine_14.png)

## 3、误差逆传播算法(BP)

**误差逆传播算法(BP)**：通过**计算误差不断逆向调整隐层神经元的连接权和阈值** 

> - 标准 BP 算法每次仅针对一个训练样例更新
> - 累积 BP 算法则根据训练集上的累积误差更新

![](../pics/machine/machine_15.png)

BP 算法流程： 

- **输入**： 训练集 $D = \{ (x_k,y_k) \}^m_{k=1}$，学习率 $\eta$ 

- **过程**： 

  > - 在 (0,1) 范围内随机初始化网络中所有连接权和阈值
  >
  > - **repeat**：
  >
  >   ​	for all $(x_k,y_k) \in D$ do
  >
  >   ​		根据当前参数和 $\hat{y_j}^k = f(\beta_j - \theta_j)$ 计算当前样本的输出 $\hat{y_k}$
  >
  >   ​		根据 $g_j = \hat{y_j}^k(1 - \hat{y_j}^k)(y_j^k - \hat{y_j}^k)$ 计算输出层神经元的梯度项 $g_j$ 
  >
  >   ​		根据 $e_h = b_h(1 - b_h)\sum^t_{j=1}w_{hj}g_j$ 计算隐含层神经元的梯度项 $e_h$ 
  >
  >   ​		根据 $\triangle_{w_{hj}} = \eta g_j b_h$、$\triangle \theta_j = - \eta g_j$、$\triangle_{v_{ih}} = \eta e_h x_i$、$\triangle_{\gamma_h} = -\eta e_h$ 更新连接权 $w_hj, v_{ih}$ 与阈值 $\theta_j, \gamma_h$ 
  >
  >   ​	end for
  >
  >   until 到达停止条件
  >
  > 参数含义： 
  >
  > - 输出层第 $j$ 个神经元的阈值用 $\theta_j$ 表示，隐含层第 $h$ 个神经元的阈值用 $\gamma_h$ 表示
  > - 输入层第 $i$ 个神经元与隐含层第 $h$ 个神经元之间的连接权为 $v_{ih}$，隐含层第 $h$ 个神经元与输出层第 $j$ 个神经元之间的连接权为 $w_{hj}$
  > - 隐含层第 $h$ 个神经元接收到的输入为 $a_h = \sum^d_{i=1}v_{ih}x_i$，输出层第 $j$ 个神经元接收到的输入为 $\beta_j = \sum^q_{h=1}w_{hj}b_h$，其中 $b_h$ 为隐含层第 $h$ 个神经元的输出
  > - 隐含层与输出层神经元使用 Sigmoid 函数

- **输出**： 连接权与阈值确定的多层前馈神经网络

---

## 4、全局最小与局部极小

> 基于梯度的搜索是使用最为广泛的参数寻优方法

- 局部极小： 参数空间中的某个点，其领域点的误差函数值均不小于该点的函数值
- 全局最小： 指参数空间中所有点的误差函数值均不小于该点的误差函数值

跳出局部极小，接近全局最小的方法： 

- 以多组不同参数值初始化多个神经网络，并训练后，选择最接近全局最小的(即：误差最小的解)

- **模拟退火**：每一步都以一定的概率接受比当前解更差的结果

  > 在每次迭代过程中，接受“次优解”的概率要随着时间的推移而逐渐降低，从而保证算法稳定

- **随机梯度下降**： 不同于标准梯度下降，在计算梯度时，加入了随机因素

  > 即使陷入局部极小点，计算出的梯度仍可能不为零，有机会跳出局部极小

## 5、其他常见神经网络

- **RBF(径向基函数)网络**： 一种单隐含层前馈神经网络，使用径向基函数作为隐含层神经元激活函数，而输出层则是对隐含层神经元输出的线性组合

  > 假定输入为 $d$ 维向量 $x$，输出为实值，则 RBF：$\varphi(x) = \sum^q_{i=1}w_i \rho(x,c_i)$ 
  >
  > - $q$ 为隐含层神经元个数，$c_i$ 和 $w_i$ 为第 $i$ 个隐含层神经元所对应的中心和权重，$\rho(x,c_i)$ 是径向基函数
  >
  > - **径向基函数**： 是某种沿径向对称的标量函数，通常定义为样本 $x$ 到数据中心 $c_i$ 之间欧式距离的单调函数
  >
  >   > 常用的高斯径向基函数： $\rho(x,c_i) = e^{-\beta_i ||x - c_i||^2}$ 
  >
  > 训练 RBF 网络的步骤： 
  >
  > - 第一步： 确定神经元中心 $c_i$，常用方式包括随机采样、聚类
  > - 第二步： 利用 BP 算法来确定参数 $w_i$ 和 $\beta_i$ 

- **ART(自适应谐振理论)网络**： 竞争型学习的重要代表，该网络由比较层、识别层、识别阈值、重置模块构成，比较好地缓解了竞争型学习中的“可塑性-稳定性窘境”，使得 ART 网络具有可进行增量学习(或在线学习)的优点

  > - **竞争型学习**： 神经网络中的**无监督学习策略**，使用时，网络的输出神经元相互竞争，每一时刻仅有几个竞争获胜的神经元被激活，其他神经元的状态被抑制
  >
  > - **比较层**： 负责接收输入样本，并将其传递给识别层神经元
  >
  > - **识别层**： 每个神经元对应一个模式类，神经元数目可在训练过程中动态增长以增加新的模式类
  >
  >   > - 接收到比较层的输入信号后，识别层神经元之间相互竞争以产生获胜神经元
  >   > - 竞争方式： 计算输入向量与每个识别层神经元所对应的模式类的代表向量之间的距离，距离最小者获胜。获胜神经元将向其他识别层神经元发生信号，抑制其激活
  >
  > - **识别阈值**： 对 ART 网络的性能影响较大，当识别阈值较高时，输入样本将会被分成比较多、比较精细的模式类；若识别阈值较低，则会产生比较少、比较粗略的模式类
  >
  >   > - 若输入向量与获胜神经元所对应的代表向量之间的**相似度大于识别阈值**，则当前输入样本将被归为该代表向量所属类别，同时网络连接权将会更新，使得以后在接收到相似输入样本时该模式类会计算出更大的相似度，从而使该获胜神经元有更大可能获胜
  >   >
  >   > - 若**相似度不大于识别阈值**，则重置模块将在识别层增设一个新的神经元，其代表向量就设置为当前输入向量
  >
  > - **可塑性**： 指神经网络要有学习新知识的能力
  >
  > - **稳定性**： 指神经网络在学习新知识时要保持对旧知识的记忆

- **SOM(自组织映射)网络**： 一种竞争学习型的无监督神经网络，能将高维输入数据映射到低维空间，同时保持输入数据在高维空间的拓扑结构，即将高维空间中相似的样本点映射到网络输出层中的邻近神经元

  > - SOM 网络中的输出层神经元以矩阵方式排列在二维空间中，每个神经元都拥有一个权向量，网络在接收输入向量后，将会确定输出层获胜神经元
  >
  >   > 获胜神经元： 决定了该输入向量在低维空间中的位置
  >
  > - 训练目标： 为每个输出层神经元找到合适的权向量，以达到保持拓扑结果的目的
  >
  > - 训练过程： 
  >
  >   - 接收到训练样本后，每个输出层神经元会计算该样本与自身携带的权向量之间的距离，距离最近的神经元成为竞争获胜者，称为最佳匹配单元
  >   - 然后，最佳匹配单元及其邻近神经元的权向量将被调整，以使得这些权向量与当前输入样本的距离缩小，直至收敛
  >
  > ![](../pics/machine/machine_17.png)

- **级联相关网络**： 结构自适应网络的重要代表，即不假定网络结构，将网络结构也当作学习的目标之一，并希望在训练过程中找到最符合数据特点的网络结构

  > 两个主要成分： 
  >
  > - **级联**： 指建立层次连接的层级结构，在开始训练时，网络只有输入层和输出层。随着训练的进行，新的隐含层神经元逐渐加入，从而创建起层级结构
  >
  >   > 当新的隐含层神经元加入时，其输入端连接权值是冻结固定的
  >
  > - **相关**： 指通过最大化神经元的输出与网络误差之间的相关性来训练相关的参数
  >
  > 优点： 级联相关网络无需设置网络层数、隐含层神经元数目，且训练速度较快
  >
  > 缺点： 在数据较小时，容易陷入过拟合
  >
  > ![](../pics/machine/machine_18.png)

- **Elman 网络**： 递归神经网络，结构类似前馈网络，但隐含层神经元的输出被反馈回来，与下一时刻输入层神经元提供的信号一起作为隐含层神经元在下一时刻的输入

  > - 递归神经网络： 允许网络中出现环形结构，从而可让一些神经元的输出反馈回来作为输入信号
  > - 注意： 隐含层神经元通常采用 Sigmoid 激活函数，而网络的训练常通过 BP 算法进行
  >
  > ![](../pics/machine/machine_19.png)

- **Boltzmann 机**： 基于能量的模型，其神经元分为显层和隐层，显层用于表示数据的输入和输出，隐层则被理解为数据的内在表达

  > - 能量模型： 为网络状态定义一个“能量”，能量最小化时网络达到理想状态，而网络的训练就是在最小化这个能量函数
  >
  > - 注意： Boltzmann 机种的神经元都是布尔型，状态 1 表示激活，状态 0 表示抑制
  >
  > - 状态向量 s 对应的 Boltzmann 机能量： $E(s) = -\sum^{n-1}_{i=1}\sum^n_{j=i+1}w_{ij}s_is_j - \sum^n_{i=1}\theta_is_i$ 
  >
  >   > $w_{ij}$ 表示神经元 $i$ 和 $j$ 之间的连接权，$\theta_i$ 表示神经元 $i$ 的阈值
  >
  > - 网络达到 Boltzmann 机分布时，状态向量 $s$ 出现的概率将仅由其能量与所有可能状态向量的能量确定： $P(s) = \frac{e^{-E(s)}}{\sum_t e^{-E(t)}}$ 
  >
  > ![](../pics/machine/machine_20.png)

# 第六章：支持向量机

## 1、间隔与支持向量

- **支持向量**： 距离超平面最近的训练样本使 $\begin{cases} w^Tx_i + b \geq +1, y_i=+1\\ w^Tx_i + b \leq -1, y_i=-1 \end{cases}$ 的等号成立
- **间隔**： 两个异类支持向量到超平面的距离之和 $\gamma = \frac{2}{||w||}$ 

![](../pics/machine/machine_21.png)

## 2、对偶问题

- **支持向量机(SVM)的基本型**： $min_{w,b} \frac12 ||w||^2, \ s.t. \ y_i(w^Tx_i + b) \geq 1, \ i = 1,2,...,m $ 

- 上式的**对偶问题**： $max_a \sum^m_{i=1}a_i - \frac12 \sum^m_{i=1}\sum^m_{j=1}a_ia_jy_iy_jx_i^Tx_j, \ s.t. \ \sum^m_{i=1}a_iy_i = 0,a_i \geq 0,i=1,2,...,m$ 

  > 解出 $a$ 后，求出 $w$ 与 $b$ 即可得到模型： $f(x) = w^Tx + b = \sum^m_{i=1}a_iy_ix_i^Tx + b$ 

- **SMO**： 先固定 $a_i$ 之外的所有参数，然后求 $a_i$ 上的极值

  > 不断执行以下步骤直至收敛： 
  >
  > - 选取一对需更新变量 $a_i$ 和 $a_j$
  > - 固定 $a_i$ 和 $a_j$ 以外的参数，求解上述“对偶问题”公式获得更新后的 $a_i$ 和 $a_j$ 

## 3、核函数

- **核函数**： 令 $\chi$ 为输入空间，$\kappa(.,.)$ 是定义在 $\chi \times \chi$ 上的对称函数，$\kappa$ 是核函数当且仅当对于任意数据 $D = \{ x_1,x_2,...,x_m \}$ 

  > 核矩阵 $K$ 总是半正定的：
  >
  > ![](../pics/machine/machine_22.png)
  >
  > 注意： 只要一个对称函数所对应的核矩阵半正定，它就能作为核函数使用

![](../pics/machine/machine_23.png)

通过函数组合得到核函数： 

- 若 $\kappa_1$ 和 $\kappa_2$ 为核函数，则对于任意正数 $\gamma_1$、$\gamma_2$，其线性组合 $\gamma_1\kappa_1 + \gamma_2 \kappa_2$ 也是核函数
- 若 $\kappa_1$ 和 $\kappa_2$ 为核函数，则核函数的值积： $\kappa_1 \bigotimes \kappa_2(x,z) = \kappa_1(x,z) \kappa_2(x,z)$ 也是核函数
- 若 $\kappa_1$ 为核函数，则对于任意函数 $g(x)$，$\kappa(x,z) = g(x)\kappa_1(x,z)g(z)$ 也是核函数

## 4、软间隔与正则化

**软间隔**： 由于无法完全在样本空间或特征空间中确定超平面，则允许支持向量机在一些样本上出错

![](../pics/machine/machine_24.png)

优化目标可写为： $min_{w,b} \frac12 ||w||^2 + C\sum^m_{i=1}l_{0/1}(y_i(w^Tx_i + b) - 1)$ 

- 其中 $C > 0$ 是一个常数，$l_{0/1}$ 是“0/1损失函数”：$l_{0/1}(z) = \begin{cases} 1,\  if \ z < 0\\ 0,\ otherwise \end{cases}$ 

- 三种常见的替代损失函数： 

  > - hinge 损失： $l_{hinge}(z) = max(0,1 - z)$ 
  > - 指数损失： $l_{exp}(z) = exp(-z)$ 
  > - 对率损失： $l_{log}(z) = log(1 + exp(-z))$ 
  >
  > ![](../pics/machine/machine_25.png)

## 5、支持向量回归

- **支持向量回归(SVR)**：假设能容忍 $f(x)$ 与 $y$ 之间最多 $\epsilon$ 的偏差，即仅当 $f(x)$ 与 $y$ 之间的差别绝对值大于 $\epsilon$ 时才计算损失

  > ![](../pics/machine/machine_26.png)

## 6、核方法

- **表示定理**： 令 $H$ 为核函数 $\kappa$ 对应的再生核希尔伯特空间，$||h||_H$ 表示 $H$ 空间中关于 $h$ 的范数，对于任意单调递增函数 $\Omega: [0,\infty] \rightarrow R$ 和任意非负损失函数 $l: R^m \rightarrow [0,\infty]$，优化问题 $min_{h \in H} F(h) = \Omega(||h||_H) + l(h(x_1),h(x_2),...,h(x_m))$ 的解为 $h^*(x) = \sum^m_{i=1}a_i \kappa(x,x_i)$ 

- **核方法**： 基于核函数的学习方法，如：通过“核化(即引入核函数)”来将线性学习器拓展为非线性学习器
- **核线性判别分析(KLDA)**：

# 第七章：贝叶斯分类器

## 1、贝叶斯决策论

- **贝叶斯决策论**：是概率框架下实施决策的基本方法，考虑如何基于概率和误判损失来选择最优的类别标记

  > - 在样本 $x$ 上的“条件风险”：$R(c_i|x) = \sum^N_{j=1}\lambda_{ij}P(c_j|x)$ 
  > - 寻找判定准则 $h: \chi \rightarrow y$ 以最小化总体风险：$R(h) = E_x[R(h(x) | x)]$ 
  >
  > 其中，$\lambda_{ij}$ 是将一个真实标记为 $c_j$ 误分类为 $c_i$ 所产生的损失

- **贝叶斯判定准则**： 为最小化总体风险，只需在每个样本上选择那个能使条件风险 $R(c|x)$ 最小的类别标记，即 $h^*(x) = arg_{c \in y} min R(c|x)$ 

  > $h^*$ 为贝叶斯最优分类器，$R(h^*)$ 为贝叶斯风险，$1 - R(h^*)$ 反映了分类器所能达到的最好性能，即通过机器学习所能产生的模型精度的理论上限
  >
  > - 若目标是最小化分类错误率，则误判损失 $\lambda_{ij}$ 为：$\lambda_{ij} = \begin{cases} 0,\  if \ i=j\\ 1,\ otherwise \end{cases}$
  >
  >   > 此时条件风险 $R(c|x) = 1 - P(c|x)$ 
  >
  > - 最小化分类错误率的贝叶斯最优分类器为： $h^* = arg_{c \in y} max P(c|x)$
  >
  >   > 即对每个样本 $x$，选择能使后验概率 $P(c|x)$ 最大的类别标记

- 估计后验概率 $P(c|x)$ 的策略： 

  - **判别式模型**： 给定 $x$，可通过直接建模 $P(c|x)$ 来预测 $c$ 

  - **生成式模型**： 先对联合概率分布 $P(x,c)$ 建模，然后再由此获得 $P(c|x)$ 

    > - $P(c|x) = \frac{P(x,c)}{P(x)}$ 
    >
    > - 基于贝叶斯定理：$P(c|x) = \frac{P(c) P(x|c)}{P(x)}$ 
    >
    >   > 难点： 类条件概率 $P(x|c)$ 是所有属性上的联合概率，难以从有限的训练样本直接估计
    >
    > 其中，$P(c)$ 是类先验概率，$P(x|c)$ 是样本 $x$ 相对于类标记 $c$ 的类条件(似然)概率，$P(x)$ 是用于归一化的证据因子

## 2、极大似然估计

- **估计类条件概率的常用策略**： 先假定其具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计

- **极大似然估计(MLE)**： 根据数据采样来估计概率分布参数

  > - 参数 $\theta_c$ 对于数据集 $D_c$ 的似然：$P(D_c|\theta_c) = \prod_{x \in D_c} P(x|\theta_c)$ 
  >
  > - 上式的连乘操作易造成下溢，改进： $LL(\theta_c) = logP(D_c|\theta_c) = \sum_{x \in D_c} logP(x|\theta_c)$ 
  >
  >   > 此时 $\theta_c$ 的极大似然估计：$\hat{\theta_c} = arg_{\theta_c}maxLL(\theta_c)$ 

## 3、朴素贝叶斯分类器

- 朴素贝叶斯分类器采用“**属性条件独立性假设**”：对已知类别，**假设所有属性相互独立**，即加每个属性独立的对分类结果发生影响

  > - 基于属性条件独立性假设，$P(c|x) = \frac{P(c) P(x|c)}{P(x)}$ 重写为： $P(c|x) = \frac{P(c) P(x|c)}{P(x)} = \frac{P(c)}{P(x)}\prod^d_{i=1}P(x_i|c)$ 
  >
  >   > $d$ 为属性数目，$x_i$ 为 $x$ 在第 $i$ 个属性上的取值

- **朴素贝叶斯分类器表达式**： $h_{nb}(x) = arg_{c \in y} maxP(c)\prod^d_{i=1}P(x_i|c)$ 

- **朴素贝叶斯分类器训练过程**： 基于训练集 D 来估计类先验概率 $P(c)$，并为每个属性估计条件概率 $P(x_i|c)$ 

  > - 先验概率： $P(c) = \frac{|D_c|}{|D|}$ 
  >
  > - 条件概率： $P(x_i|c) = \frac{|D_{c,x_i}|}{|D_c|}$
  >
  >   > $D_{c,x_i}$ 表示 $D_c$ 中在第 $i$ 个属性上取值为 $x_i$ 的样本组成的集合

## 4、半朴素贝叶斯分类器

- **半朴素贝叶斯分类器**： **放松对属性条件独立性的假设约定**，即适当考虑一部分属性间的相互依赖信息，从而既不需及逆行完全联合概率计算，又不至于彻底忽略了比较强的属性依赖关系

- **独依赖估计(ODE)**： 假设每个属性在类别外最多仅依赖一个其他属性，即 $P(c|x) \propto P(c)\prod^d_{i=1}P(x_i|c,pa_i)$ 

  > $pa_i$ 为属性 $x_i$ 所依赖的属性，称为 $x_i$ 的父属性

- **超父属性**： 假设所有属性都依赖同一个属性

- 确定超父属性方法：

  - **SPOED(Super-Parent ODE) 方法**：通过模型选择确定超父属性

  - **TAN 方法**： 在最大带权生成树算法的基础上，通过以下步骤将属性间依赖关系约简为下图树形结构

    > ![](../pics/machine/machine_27.png)
    >
    > **步骤**： 
    >
    > 1. 计算任意两个属性之间的条件互信息： $I(x_i,x_j|y) = \sum_{x_i,x_j;c \in y} P(x_i,x_j|c)log \frac{P(x_i,x_j|c)}{P(x_i|c)P(x_j|c)}$ 
    > 2. 以属性为结点构建完全图，任意两个结点之间的权重设为 $I(x_i,x_j|y)$ 
    > 3. 构建此完全图的最大带权生成树，挑选根变量，将边置为有向
    > 4. 加入类别结点 $y$，增加从 $y$ 到每个属性的有向边

  - **AODE 方法**： 基于集成学习机制、更为强大的独依赖分类器。尝试将每个属性作为超父来构建 SPODE，然后将那些具有足够训练数据支撑的 SPODE 集成起来作为最终结果，即 $P(c,x) \propto \sum^d_{i=1}P(c,x_i)\prod^d_{j=1}P(x_j|c,x_i), \ |D_{x_i}| \geq m'$ 

    > - $D_{x_i}$ 是在第  $i$ 个属性上取值为 $x_i$ 的样本的集合，$m'$ 为阈值常数
    >
    > - AODE 需估计 $P(c,x_i)$ 和 $P(x_j|c,x_i)$：
    >
    >   $\hat{P}(c,x_i) = \frac{|D_{c,x_i}| + 1}{|D| + N_i}$ 与 $\hat{P}(x_j|c,x_i) = \frac{|D_{c,x_i,x_j}| + 1}{|D_{c,x_i}| + N_j}$ 
    >
    >   > 其中，$N_i$ 是第 $i$ 个属性可能的取值数，$D_{c,x_i}$ 是类别为 c 且在第 $i$ 个属性上取值为 $x_i$ 的样本集合，$D_{c,x_i,x_j}$ 是类别为 c 且在第 $i$ 和第 $j$ 个属性上取值分别为 $x_i$ 和 $x_j$ 的样本集合

## 5、贝叶斯网

- **贝叶斯网(信念网)**：借助有向无环图(DAG) 来刻画属性之间的依赖关系，并使用条件概率表(CPT)来描述属性的联合概率分布

  > 贝叶斯网 $B$ 由机构 G 和参数 $\Theta$ 构成，即 $B = (G,\Theta)$：
  >
  > - **网络结构 G**：是一个有向无环图，其每个结点对应于一个属性，若两个属性有直接依赖关系，则它们由一条边连接起来
  >
  > - **参数 $\Theta$**： 定量描述这种依赖关系
  >
  >   > 假设属性 $x_i$ 在 G 中的父结点集为 $\pi_i$，则 $\Theta$ 包含了每个属性的条件概率表 $\theta_{x_i|\pi_i} = P_B(x_i|\pi_i)$ 

- **结构**： 贝叶斯网结构有效地表达了属性间的条件独立性

  > - 给定父结点集，贝叶斯网假设每个属性与它的非后裔属性独立
  > - $B = (G,\Theta)$ 将属性 $x_1,...,x_d$ 的联合概率分布定义为： $P_B(x_1,...,x_d) = \prod^d_{i=1}P_B(x_i|\pi_i) = \prod^d_{i=1}\theta_{x_i|\pi_i}$ 
  >
  > ![](../pics/machine/machine_28.png)
  >
  > - 在“同父”结构中，给定父节点 $x_1$ 的取值，则 $x_3$ 与 $x_4$ 条件独立
  >
  > - 在“顺序”结构中，给定 x 的值，则 y 与 z 条件独立
  >
  > - 在“V 型”结构中，给定子结点 $x_4$ 的取值，$x_1$ 与 $x_2$ 必不独立
  >
  >   > 注： 若 $x_4$ 的取值完全未知，则 V 型结构下 $x_1$ 与 $x_2$ 相互独立

- **学习**： 若网络结构已知，即属性间的依赖关系已知，则贝叶斯网的学习过程相对简单，只需通过对训练样本“计数”，估计出每个结点的条件概率表即可

  > - 贝叶斯网学习的首要任务： 根据训练数据集来找出结构最恰当的贝叶斯网
  > - 评分搜索： 先定义一个评分函数，一次评估贝叶斯网域训练数据的契合程度，然后基于这个评分函数来寻找结构最优的贝叶斯网

- **推断**： 贝叶斯网训练好后，通过一些属性变量的观测值来推断其他属性变量的取值

  > - **吉布斯采样**： 贝叶斯网的近似推断常用方法，一种随机采样法
  >
  > ![](../pics/machine/machine_29.png)

## 6、EM 算法

- **EM 算法**： 估计参数隐变量的利器，即若参数 $\Theta$ 已知，则可根据训练数据推断出最优隐变量 $Z$ 的值(E 步)；反之，若 $Z$ 的值已知，则可对参数 $\Theta$ 做极大似然估计(M 步)

  > X 表示已观测变量集，Z 表示隐变量(未观测变量)集，$\Theta$ 表示模型参数

- **EM 算法原型**： 以初始值 $\Theta^0$ 为起点，，可迭代执行以下步骤直至收敛：

  - 基于 $\Theta^t$ 推断隐变量 Z 的期望，记为 $Z^t$ 
  - 基于已观测变量 X 和 $Z^t$ 对参数 $\Theta$ 做极大似然估计，记为 $\Theta^{t+1}$ 

- **EM 算法步骤**： 不取 Z 的期望，而是基于 $\Theta^t$ 计算隐变量 Z 的概率分布 $P(Z|X,\Theta^t)$

  - **E 步**：以当前参数 $\Theta^t$ 推断隐变量分布 $P(Z|X,\Theta^t)$，并计算对数似然 $LL(\Theta|X,Z)$ 关于 Z 的期望 $Q(\Theta|\Theta^t) = E_{Z|X;\Theta^t} LL(|Theta|X,Z)$ 

  - **M 步**： 寻找参数最大化期望似然，即 $\Theta^{t+1} = arg_{\Theta} max Q(\Theta|\Theta^t)$ 

> EM 算法使用两个步骤交替计算： 
>
> - 第一步是期望(E)步，利用当前估计的参数值来计算对数似然的期望值
> - 第二步是最大化(M)步，寻找能使 E 步产生的似然期望最大化的参数值
> - 然后新得到的参数值重新被用于 E 步，直至收敛到局部最优解

# 第八章：集成学习

## 1、个体与集成

- **集成学习**： 通过构建并结合多个学习器来完成学习任务，又称为多分类器系统、基于委员会的学习

  > 先产生一组“个体学习器”，再用某种策略将它们结合起来
  >
  > ![](../pics/machine/machine_30.png)

- **集成学习方法分类**： 根据个体学习器的生成方式
  - 第一种： 个体学习器间存在**强依赖**关系、必须串行生成的序列方法，如：Boosting
  - 第二种： 个体学习器间**不存在强依赖**关系、可同时生成的并行化方法，如： Bagging、随机森林

## 2、Boosting

- **Boosting**： 可将弱学习器提升为强学习器的算法
- **工作机制**： 
  - 先从初始训练集训练出一个基学习器，再根据学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注，然后基于调整后的样本分布来训练下一个基学习器
  - 如此重复，直至基学习器数目达到事先指定的值 T，最终将这 T 个基学习器进行加权结合

- **AdaBoost 算法**： ==推导没看懂== 

  > ![](../pics/machine/machine_31.png)

## 3、Bagging 与随机森林

- **Bagging**： 并行式集成学习

  > 基本流程： 
  >
  > - 基于“自助采样法”，即给定包含 m 个样本的数据集，先随机取出一个样本放入采样集中，再把该样本放回初始数据集，使得下次采样时该样本仍有可能被选中
  >
  >   > 自助采样优点： 基学习器只使用了初始训练集中约 63.2% 的样本，剩下约 36.8% 的样本可用作验证集来对泛化性能进行“**包外估计**”
  >
  > - 经过 m 次随机采样操作，得到含 m 个样本的采样集
  >
  > - 得到 T 个含 m 个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器结合
  >
  > 在对预测输出结合时，Bagging 对分类任务使用简单投票法，对回归任务使用简单平均法
  >
  > ![](../pics/machine/machine_32.png)
  >
  > - 学习复杂度：$T(O(m) + O(s))$，其中基学习器的复杂度为 $O(m)$  
  >
  > - 泛化误差的包外估计： $\epsilon^{oob} = \frac{1}{|D|}\sum_{(x,y) \in D}I(H^{oob}(x) \neq y)$ 
  >
  >   > 其中 $H^{oob}(x) = arg_{y \in Y} max \sum^T_{t=1}I(h_t(x) = y) I(x \notin D_t)$ 
  >   >
  >   > - $D_t$ 表示 $h_t$ 实际使用的训练样本集
  >   > - $H^{oob}(x)$ 表示对样本 $x$ 的包外预测，即仅考虑未使用 $x$ 训练的基学习器在 $x$ 上的预测

- **随机森林(RF)**： Bagging 的扩展变体，以决策树为基学习器，并在决策树的训练过程中引入随机属性选择

  > - 传统决策树： 在选择划分属性时，在当前结点的属性集合中选择一个最优属性
  > - RF 的决策树： 对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含 $\kappa$ 个属性的子集，然后再从这个子集中选择一个最优属性用于划分

## 4、结合策略

- 学习器结合的好处： 

  - 从统计上： 由于学习任务的假设空间很大，多个假设在训练集上达到同等性能，此时若使用单学习器可能因误选而导致泛化性能不佳，结合多个学习器会减小该风险
  - 从计算上： 学习算法往往会陷入局部极小，通过多次运行后结合，可降低陷入糟糕局部极小点的风险
  - 从表示上： 某些学习任务的真实假设可能不在当前学习算法所考虑的假设空间中，但结合多个学习器，由于相应的假设空间有所扩大，可能学得更好的近似

  ![](../pics/machine/machine_33.png)

- 常见的**结合策略**： 

  - **平均法**： 

    - **简单平均法**： $H(x) = \frac1T\sum^T_{i=1}h_i(x)$ 
    - **加权平均法**： $H(x) = \sum^T_{i=1}w_ih_i(x)$，$w_i$ 是个体学习器 $h_i$ 的权重，$\sum^T_{i=1}w_i = 1$ 

  - **投票法**： 

    - **绝对多数投票法**： $H(x) = \begin{cases} c_j,\ \ \ \ \ \ \ \  if \ \sum^T_{i=1}h^j_i(x) >0.5\sum^N_{k=1}\sum^T_{i=1}h^k_i(x)\\ reject,\ otherwise \end{cases}$ 
    - **相对多数投票法**：$H(x) = c_{arg_jmax\sum^T_{i=1} h_i^j(x)}$ 
    - **加权投票法**： $H(x) = c_{arg_jmax\sum^T_{i=1}w_i h_i^j(x)}$，$w_i$ 是个体学习器 $h_i$ 的权重，$\sum^T_{i=1}w_i = 1$ 

  - **学习法**： 通过另一个学习器来进行结合

    > Stacking 法：先从初始数据集训练出初级学习器，然后“生成”一个新数据集用于训练次级学习器
    >
    > - 初级学习器：个体学习器
    > - 次级学习器或元学习器： 用于结合的学习器
    >
    > ![](../pics/machine/machine_34.png)

## 5、多样性

- **误差-分歧分解**： 个体学习器准确性越高、多样性越大，则集成越好

  > $E = \overline{E} - \overline{A}$ 
  >
  > - $\overline{E} = \sum^T_{i=1}w_iE_i$ 表示个体学习器泛化误差的加权均值
  > - $\overline{A} = \sum^T_{i=1}w_iA_i$ 表示个体学习器的加权分歧值

- **多样性度量**： 用于度量集成个体分类器的多样性，即估算个体学习器的多样化程度

  > ![](../pics/machine/machine_35.png)
  >
  > 常见的多样性度量： 
  >
  > - 不合度量： $dis_{ij} = \frac{b+c}{m}$，$dis_{ij}$ 的值域为 [0,1]，值越大则多样性越大
  >
  > - 相关系数： $\rho_{ij} = \frac{ad - bc}{\sqrt{(a+b)(a+c)(c+d)(b+d)}}$，$\rho_{ij}$ 的值域为 [-1,1]
  >
  >   > - 若 $h_i$ 与 $h_j$ 无关，则值为 0
  >   > - 若 $h_i$ 与 $h_j$ 正相关，则值为正，否则为负
  >
  > - Q-统计量： $Q_{ij} = \frac{ad - bc}{ad + bc}$，$Q_{ij}$ 与相关系数 $\rho_{ij}$ 符号相同，且 $|Q_{ij}| \leq |\rho_{ij}|$ 
  >
  > - $\kappa$-统计量： $\kappa = \frac{p_1 - p_2}{1 - p_2}$，$p_1$ 是两个分类器取得一致的概率，$p_2$ 是两个分类器偶然达成一致的概率
  >
  >   > 由数据集 D 估算：$p_1 = \frac{a+d}{m}$ 和 $p_2 = \frac{(a+b)(a+c) + (c+d)(b+d)}{m^2}$ 

- **多样性增强**： 在学习过程中引入随机性，如：对数据样本、输入属性、输出表示、算法参数进行扰动

  - **数据样本扰动**： 基于采样法，从初始数据集中产生不同的数据子集，再利用不同的数据子集训练出不同的个体学习器

  - **输入属性扰动**： 不同的“子空间(属性子集)”提供了观察数据的不同视角

    > 随机子空间算法： 从初始属性集中抽取若干个属性子集，再基于每个属性子集训练一个基学习器
    >
    > ![](../pics/machine/machine_36.png)

  - **输出表示扰动**： 对输出表示进行操纵以增强多样性

  - **算法参数扰动**： 

    - 参数影响较大的算法： 显示的通过正则化项来强制个体神经网络使用不同的参数
    - 参数较少的算法： 通过将其学习过程中某些环节用其他类似方式代替，从而达到扰动的目的

# 第九章：聚类

## 1、聚类任务

- **聚类**： 将数据集中的样本划分为若干个不相交的子集，每个子集称为“簇”

## 2、性能度量

- 聚类性能度量分类：

  - **外部指标**： 将聚类结果与某个“参考模型”进行比较

    > - Jaccard 系数(JC)：$JC = \frac{a}{a + b +c}$ 
    > - FM 指数(FMI)： $FMI = \sqrt{\frac{a}{a+b}*\frac{a}{a+c}}$ 
    > - Rand 指数(RI)： $RI = \frac{2(a+d)}{m(m-1)}$ 

  - **内部指标**： 直接考察聚类结果而不利用任何参考模型

    > - DB 指数(DBI)： $DBI = \frac1k\sum^k_{i=1}max_{j \neq i}(\frac{avg(C_i) + avg(C_j)}{d_{cen}(\mu_i,\mu_j)})$ 
    > - Dunn 指数(DI)： $DI = min_{1 \leq i \leq k}\{ min_{j \neq i}(\frac{d_{min}(C_i,C_j)}{max_{1 \leq l \leq kdiam(C_1)}}) \}$ 

## 3、距离计算

- 距离向量的基本性质：
  - 非负性： $dist(x_i,x_j) \geq 0$ 
  - 同一性： $dist(x_i,x_j) = 0$ 当且仅当 $x_i = x_j$ 
  - 对称性： $dist(x_i,x_j) = dist(x_j,x_i)$ 
  - 直递性： $dist(x_i,x_j) \leq dist(x_i,x_k) + dist(x_k,x_j)$ 

- 闵可夫斯基距离： $dist_{mk}(x_i,x_j) = (\sum^n_{u=1}|x_{iu} - x_{ju}|^p)^{\frac1p}$ 
  - $p \geq 1$ 时，满足上述“距离向量”的四条基本性质
  - $p = 2$ 时，闵可夫斯基距离变为欧氏距离：$dist_{ed}(x_i,x_j) = ||x_i - x_j||_2 = \sqrt{\sum^n_{u=1}|x_{iu} - x_{ju}|^2}$ 
  - $p = 1$ 时，闵可夫斯基距离变为曼哈顿距离： $dist_{man}(x_i,x_j) = ||x_i - x_j||_1 = \sum^n_{u=1}|x_{iu} - x_{ju}|$ 

- 属性划分： 

  - 连续属性： 在定义域上有无穷多个可能的取值
  - 离散属性： 在定义域上是有限个取值

  ---

  - 无序属性： **不能**直接在属性值上计算距离

    > - VDM 距离： $VDM_{\rho}(a,b) = \sum^k_{i=1}|\frac{m_{u,a,i}}{m_{u,a}} - \frac{m_{u,b,i}}{m_{u,b}}|^p$ 
    > - 闵可夫斯基距离与 VDM 结合： $MinkoVDM_p(x_i,x_j) = (\sum^{n_c}_{u=1}|x_{iu} - x_{ju}|^p + \sum^n_{u=n_c+1}VDM_{\rho}(x_{iu},x_{ju}))^{\frac1p}$ 

  - 有序属性： 能直接在属性值上计算距离

## 4、原型聚类

**原型聚类**： 基于原型的聚类，算法先对原型进行初始化，然后对原型进行迭代更新求解

- **k 均值算法**： 

  > - 最小化平方误差： $E = \sum^k_{i=1} \sum_{x \in C_i}||x - \mu_i||^2_2$，其中 $\mu_i = \frac{1}{C_i}\sum_{x \in C_i}x$ 
  >
  >   > - 刻画了簇内样本围绕均值向量的紧密程度
  >   > - E 值越小，则簇内样本相似度越高
  >
  > - k 均值算法采用贪心策略，即通过迭代优化来近似求解
  >
  >   ![](../pics/machine/machine_37.png)

- **学习向量量化(LVQ)**： 假设数据样本带有类别标记，学习过程利用样本的监督信息来辅助聚类

  > ![](../pics/machine/machine_38.png)

- **高斯混合聚类**： 采用概率模型来表达聚类原型

  > ![](../pics/machine/machine_39.png)

## 5、密度聚类

- **密度聚类**： 假设聚类结构能通过样本分布的紧密程度确定

- **DBSCAN 算法**： 基于一组“邻域”参数$(\epsilon, MinPts)$来刻画样本分布的紧密程度

  > 概念定义： 
  >
  > - **$\epsilon$-邻域**： 对 $x_j \in D$，$\epsilon$-邻域包含样本集 D 中与 $x_j$ 的距离不大于 $\epsilon$ 的样本，即 $N_{\epsilon}(x_j) = \{ x_i \in D | dist(x_i,x_j) \leq \epsilon \}$ 
  >
  > - **核心对象**： 若 $x_j$ 的 $\epsilon$-邻域至少包含 MinPts 个样本，即 $|N_{\epsilon}(x_j)| \geq MinPts$，则 $x_j$ 是一个核心对象
  >
  > - **密度直达**： 若 $x_j$ 位于 $x_i$ 的 $\epsilon$-邻域中，且 $x_i$ 是核心对象，则称 $x_j$ 由 $x_i$ 密度直达
  >
  > - **密度可达**： 对 $x_i$ 和 $x_j$，若存在样本序列 $p_1,...,p_n$，其中 $p_1 = x_i,p_n = x_j$ 且 $p_{n+1}$ 由 $p_i$ 密度直达，则称 $x_j$ 由 $x_i$ 密度可达
  >
  > - **密度相连**： 对 $x_i$ 与 $x_j$，若存在 $x_k$ 使得 $x_i$ 与 $x_j$ 均由 $x_k$ 密度可达，则称 $x_i$ 与 $x_j$ 密度相连
  >
  >   ![](../pics/machine/machine_40.png)
  >
  > ---
  >
  > 算法流程： 先任选数据集中的一个核心对象为"种子"，再由此出发确定相应的聚类簇
  >
  > ![](../pics/machine/machine_41.png)

## 6、层次聚类

- **层次聚类**： 在不同层次对数据集进行划分，从而形成树形的聚类结构

- **AGNES 算法**： 采用自底向上聚合策略

  > 流程： 
  >
  > - 先将数据集中的每个样本看作一个初始聚类簇，然后在算法运行的每一步中找出距离最近的两个聚类簇进行合并
  > - 不断重复该过程，直至达到预设的聚类簇个数
  >
  > ---
  >
  > 距离计算式子： 
  >
  > - 最小距离： $d_{min}(C_i,C_j) = min_{x \in C_i,z \in C_j}dist(x,z)$ 
  > - 最大距离： $d_{max}(C_i,C_j) = max_{x \in C_i,z \in C_j} dist(x,z)$ 
  > - 平均距离： $d_{avg}(C_i,C_j) = \frac{1}{|C_i||C_j|}\sum_{x \in C_i}\sum_{z \in C_j} dist(x,z)$ 
  >
  > ![](../pics/machine/machine_42.png)

# 第十章：降维与度量学习

## 1、k 近邻学习

- **k 近邻(KNN)学习**： 监督学习法，给定测试样本，基于某种距离度量找出训练集中与其最靠近的 k 个训练样本，然后基于这 k 个“邻居”的信息来进行预测，是一种懒惰学习法

  > - 分类任务中，使用“投票法”，即选择这 k 个样本中出现最多的类别标记作为预测结果
  > - 回归任务中，使用“平均法”，即将这 k 个样本的实值输出标记的平均值作为预测结果
  > - 还可依据距离远近进行加权平均或加权投票，距离越近的样本权重越大
  >
  > k 取值不同时，分类结果会显著不同：
  >
  > ![](../pics/machine/machine_43.png)

- 学习方式分类：
  - **懒惰学习**： 在训练阶段仅仅把样本保存起来，训练时间开销为零，待收到测试样本后再进行处理
  - **急切学习**： 在训练阶段就对样本进行学习处理的方法

## 2、低维嵌入

- **密采样**： 训练样本的采样密度足够大，即在测试样本 x 附近任意小的 $\delta$ 距离范围内总能找到一个训练样本

- **维数灾难**： 在高维情形下，出现的数据样本稀疏、距离计算困难

- **降维**： 缓解维数灾难，即通过某种数学变换将原始高维属性空间转变为一个低维子空间

- **多维缩放(MDS)**：经典的降维方法

  > 算法过程：
  >
  > - 输入： 距离矩阵 $D \in R^{m \times m}$，其元素 $dist_{ij}$ 为样本 $x_i$ 到 $x_j$ 的距离，低维空间维数 $d'$ 
  >
  > - 过程：
  >
  >   1. 根据式 $dist_{i.}^2 = \frac1m \sum^m_{j=1}dist^2_{ij}$、$dist^2_{.j} = \frac1m \sum^m_{i=1}dist^2_{ij}$、$dist^2_{..} = \frac{1}{m^2}\sum^m_{i=1}\sum^m_{j=1}dist^2_{ij}$ 
  >
  >      > $dist_{ij}^2 = b_{ii} + b_{jj} - 2 b_{ij}$ 
  >
  >   2. 根据式 $b_{ij} = -\frac12(dist^2_{ij} - dist^2_{i.} - dist^2_{.j} + dist^2_{..})$ 计算矩阵 B
  >
  >   3. 对矩阵 B 做特征值分解
  >
  >   4. 取 $\overline{\Lambda}$ 为 $d'$ 个最大特征值所构成的对角矩阵，$\overline{V}$ 为相应的特征向量矩阵
  >
  > - 输出： 矩阵 $\overline{V} \overline{\Lambda}^{\frac12} \in R^{m \times d'}$，每行是一个样本的低维坐标

## 3、主成分分析

- **主成分分析(PCA)**： 一种降维方法

  ![](../pics/machine/machine_44.png)

## 4、核化线性降维

- **线性降维**： 假设从高维空间到低维空间的函数映射是线性的
- **核化线性降维**： 基于核技巧对线性降维方法进行“核化”

## 5、流形学习

- **流行**： 在局部与欧氏空间同胚的空间，即在局部具有欧氏空间的性质，能用欧氏距离来进行距离计算

- **流行学习**： 借鉴拓扑流形概念的降维方法

  - **等度量映射(Isomap)**： 对每个点基于欧氏距离找出其邻近点，然后建立一个邻近连接图

    > - 实质： 计算两点之间测地线距离问题，就转变为计算近邻连接图上两点之间的最短路径问题
    > - 基本出发点： 认为低维流形嵌入到高维空间后，直接在高维空间中计算直线距离具有误导性
    >
    > ![](../pics/machine/machine_45.png)
    >
    > 近邻图构建的方法： 
    >
    > - 法一： 指定近邻点个数，如欧氏距离最近的 k 个点为近邻点
    > - 法二： 指定距离阈值 $\epsilon$，距离小于 $\epsilon$ 的点被认为是邻近点

  - **局部线性嵌入(LLE)**： 试图保证邻域内样本之间的线性关系

    > ![](../pics/machine/machine_46.png)
    >
    > 式(10.27)： $min_{w_1,...,w_m}\sum^m_{i=1}||x_i - \sum_{j \in Q_i}w_{ij}x_j||^2_2, \ \ s.t. \ \sum_{j \in Q}w_{ij} = 1$ 
    >
    > 式(10.30)： $M = (I - W)^T(I - W)$ 

## 6、度量学习

- **度量学习**： 直接尝试“学习”出一个合适的距离度量

# 第十一章：特征选择与稀疏学习

## 1、子集搜索与评价

- **特征选择**： 从给定的特征集中选择出相关特征子集的过程

  > - 注意： 特征选择过程必须确保不丢失重要特征
  >
  > - 冗余特征： 其所包含的信息能从其他特征中推演出来

- 特征选择的原因： 

  - 第一：特征选择可以**减轻维数灾难**
  - 第二： 去除不相关特征会**降低学习任务的难度**

- **选取特征子集**的过程：先产生一个“候选子集”，评价其好坏，基于评价结果产生下一个候选子集，直至找到更好的候选子集为止

  - 第一：**子集搜索**

    > - **前向搜索**： 
    >   - 给定特征集合 $\{ a_1,a_2,...a_d \}$，首先假定 $\{ a_2 \}$ 最优并作为第一轮的候选子集
    >   - 然后加入一个特征构成 $\{ a_2,a_4 \}$，若优于 $\{a_2\}$，则将 $\{ a_2,a_4 \}$ 作为本轮的候选子集
    >   - 直到在第 $k+1$ 轮时，最优的候选 (k+1) 特征子集不如上一轮的候选子集，则停止生成候选子集 
    > - **后向搜索**： 类似的，从完成的特征集合开始，每次尝试去掉一个无关特征
    > - **双向搜索**： 每轮增加选定相关特征、同时减少无关特征的策略
    >
    > 局限： 上述策略均为贪心，仅考虑使本轮选定集最优

  - 第二： **子集评价**，即对每个候选特征子集，可通过信息增益、信息熵等来作为评价准则

- 常见的**特征选择方法**： 过滤式、包裹式、嵌入式

## 2、过滤式选择

- **过滤式方法**： 先对数据集进行特征选择，然后再训练学习器，特征选择过程与后续学习器无关

  > 注： 相当于先用特征选择过程对初始特征进行“过滤”，再用过滤后的特征来训练模型

- **Relief 方法**： 设计了一个“相关统计量”来度量特征的重要性

  > - 该统计量是一个向量，其每个分量分别对应一个初始特征，而特征子集的重要性由子集中每个特征所对应的相关统计量分量之和来决定
  > - 只需指定阈值 $\tau$，然后选择比 $\tau$ 大的相关统计量分量所对应的特征即可；也可指定欲选取的特征个数 k，然后选择相关统计量分量最大的 k 个特征
  >
  > ---
  >
  > - Relief 秩序在数据集采样上估计相关统计量
  > - Relief 的时间开销随采样次数以及原始特征数线性增长
  > - Relief 用于二分类问题，Relief-F 能处理多分类问题

## 3、包裹式选择

- **包裹式特征选择**： 直接把最终要使用的学习器的性能作为特征子集的评价准则

  > - 目的： 为给定学习器选择最有利于其性能、“量身定做”的特征子集

- **LVW 方法**： 在拉斯维加斯方法框架下使用随机策略来进行子集搜索，并以最终分类器的误差为特征子集评价准则

  > ![](../pics/machine/machine_47.png)

## 4、嵌入式选择与 L1 正则化

- **嵌入式特征选择**： 将特征选择过程与学习器训练过程融为一体，两者在同一个优化过程中完成，即在学习器训练过程中自动进行了特征选择

- 岭回归： 通过引入 $L_2$ 范数正则化，能显著降低过拟合的风险，即 $min_w \sum^m_{i=1}(y_i - w^Tx_i)^2 + \lambda||w||^2_2$ 

  > - $L_1$ 范数：$min_w \sum^m_{i=1}(y_i - w^Tx_i)^2 + \lambda||w||_1$ 

## 5、稀疏表示与字典学习

- **稀疏性的种类**：

  -  **特征具有“稀疏性”**，即矩阵中的许多列与当前学习任务无关，通过特征选择去除这些无关列

    > 学习器训练过程中，仅需在较小的矩阵上进行，学习任务的难度会降低，计算和存储开销会减少，学得模型的可解释性也会提高

  - 数据集具有很多零元素，但并不是以整列、整行形式存在

    > 该稀疏性对学习任务有利，例如：线性支持向量机对文本数据的处理

- **字典学习**： 为普通稠密表达的样本找到合适的字典，将样本转化为合适的稀疏表示形式，从而使学习任务得以简化，模型复杂度得以降低

  > 字典学习的最简单形式： $min_B||X - BA||_F^2 = min_{b_i}||E_i - b_ia^i||^2_F$ 
  >
  > 其中 $X = (x_1,x_2,...,x_m) \in R^{d \times m}, A = (a_1,a_2,...,a_m) \in R^{k \times m}, ||*||_F$ 是矩阵的 Frobenius 范数，$E_i = \sum_{j \neq i}b_ja^j$ 是固定的
  >
  > ---
  >
  > - 字典学习更侧重于学得字典的过程
  > - 稀疏编码更侧重于样本进行稀疏表达的过程

## 6、压缩感知

- **奈奎斯特采样定理**： 令采样频率达到模拟信号最高频率的两倍，则采样后的数字信号就保留了模拟信号的全部信息

- **压缩感知**： 用于解决由于信息压缩、传输丢包等造成的信息丢失问题

  > 长度 m 的离散信号 x 采样得到长度为 n 的采样后信号 y，$n << m$，即$y = \Phi x = \Phi \Psi s = As$ 
  >
  > - $A = \Phi \Psi \in R^{n \times m}$ 作用类似字典，能将信号转换为稀疏表示
  > - $x = \Psi s$ 通过恢复 s 来恢复信号 x
  > - $\Phi \in R^{n \times m}$ 是对信号 x 的测量矩阵

- **压缩感知的关注点**： 如何利用信号本身所具有的稀疏性，从部分观测样本中恢复原信号
- **压缩感知的两个阶段**： 
  - **感知测量**： 关注如何对原始信号进行处理以获得稀疏样本表示
  - **重构恢复**： 关注如何基于稀疏性从少量观测中恢复原信号

- **限定等距性(RIP)**： 对矩阵 $A \in R^{n \times m}$ 存在常数 $\delta_k \in (0,1)$ 使得对于任意向量 s 和 A 的所有子矩阵 $A_k \in R^{n \times k}$ 有 $(1 - \delta_k)||s||^2_2 \leq ||A_ks||^2_2 \leq (1 + \delta_k)||||^2_2$ 

  > - 从 y 中恢复稀疏信号 s，进而恢复 x，即 $min_s||s||_1 \ \ \ s.t. \ y = As$ 

- **基寻踪去噪**： $min_s||s||_1 \ \ \ s.t. \ y = As$ 转化为 LASSO 的等价形式再通过近端梯度下降法求解

- **矩阵补全**： 通过已知的部分信号，基于压缩感知的思想恢复出完整信号

  > - $min_X \ \ rank(X) \ \ \ s.t. \ (X)_{ij} = (A)_{ij}, (i,j) \in \Omega$
  >
  >   > $X$ 表示需恢复的稀疏信号，$rank(X)$ 表示矩阵 $X$ 的秩，$A$ 表示已观测信号，$\Omega$ 是 $A$ 中非“?” 元素(已确定分类) $(A)_{ij}$ 的下标 $(i,j)$ 的集合

# 第十二章：计算学习理论

## 1、基础知识

- **计算学习理论**： 研究关于通过“计算”来进行“学习”的理论，即关于机器学习的理论基础
- **目的**： 分析学习任务的困难本质，为学习算法提供理论保证，并根据分析结果指导算法设计

## 2、PAC 学习

- **目标概念**： 令 c 是从样本空间 $\chi$ 到标记空间 $\Upsilon$ 的映射，它决定示例 $x$ 的真实标记 $y$，对人恶化样例 $(x,y)$ 有 $c(x) = y$ 成立
- **概念类**： 所有希望学得的目标概念所构成的集合，用 $\zeta$ 表示
- **假设空间**： 给定学习算法 $\xi$ 所考虑的所有可能概念的集合，用 $\Eta$ 表示

- **PAC(概率近似正确)辨识**： 对 $0 < \epsilon, \delta < 1$，所有 $c \in \zeta$ 和分布 $D$，若存在学习算法 $\xi$，其输出假设 $h \in H$ 满足 $P(E(h)) \leq \epsilon \geq 1- \delta$，则称学习算法 $\xi$ 能从假设空间 $H$ 中 PAC 辨识概念类 $\zeta$ 
- **PAC 可学习**： 令 m 表示从分布 $D$ 中独立同分布采样得到的样例数目 $0 < \epsilon, \delta < 1$ 对所有分布 $D$，若存在学习算法 $\xi$ 和多项式函数 $poly(.,.,.)$，使得对于任何 $m \geq poly(\frac{1}{\xi}, \frac{1}{\delta}, size(x), size(c))$，$\xi$ 能从任何假设空间 $H$ 中 PAC 辨识概念类 $\zeta$，则称概念类 $\zeta$ 对假设空间 $H$ 是 PAC 可学习
- **PAC 学习算法**： 若学习算法 $\xi$ 使概念类 $\zeta$ 为 PAC 可学习的，且 $\xi$ 的运行时间也是多项式函数 $poly(\frac{1}{\xi}, \frac{1}{\delta}, size(x), size(c))$，则称概念类 $\zeta$ 是高效 PAC 可学习，$\xi$ 为概念类 $\zeta$ 的 PAC 学习算法
- **样本复杂度**： 满足 PAC 学习算法 $\xi$ 所需的 $m \geq poly(\frac{1}{\xi}, \frac{1}{\delta}, size(x), size(c))$ 中最小的 m 称为学习算法 $\xi$ 的样本复杂度

## 3、有限假设空间

- **可分情形**： 目标概念 c 属于假设空间 H，即 $c \in H$ 

  > - **简单的学习策略**： 因任何在训练集 D 上出现标记错误的假设肯定不是目标概念 c，因此只需保留与 D 一致的假设，剔除与 D 不一致假设即可

- **不可分情形**： 目标概念 c 不存在于假设空间 H 中，即 $c \notin H$ 

  > - **引理 12.1**： 若训练集 D 包含 m 个从分布 $D$ 上独立同分布采样而得的样例 $0 < \epsilon < 1$，则对任意 $h \in H$，有 
  >
  >   ​					$P(\hat{E}(h) - E(h) \geq \epsilon) \leq exp(-2m\epsilon^2)$ 
  >
  >   ​					$P(E(h) - \hat{E}(h) \geq \epsilon) \leq exp(-2m\epsilon^2)$
  >
  >    					$P(|E(h) - \hat{E}(h)| \geq \epsilon) \leq 2exp(-2m\epsilon^2)$ 
  >
  > - **推论 12.1**： 若训练集 D 包含 m 个分布 $D$ 上独立同分布采样而得的样例 $0 < \epsilon < 1$，则对任意 $h \in H$，式 $\hat{E}(h) - \sqrt{\frac{ln(2/\delta)}{2m}} \leq E(h) \leq \hat{E}(h) + \sqrt{\frac{ln(2/\delta)}{2m}}$ 以至少 $1 - \delta$ 的概率成立
  >
  >   > 上述推论表明，样例数目 m 较大时，h 的经验误差是其泛化误差很好的近似
  >
  > - **定理 12.1**： 若 $H$ 为有限假设空间，$0 < \delta < 1$，则对任意 $h \in H$，有 $P(|E(h) - \hat{E}(h)| \leq \sqrt{\frac{ln|H| + ln(2/\delta)}{2m}}) \geq 1 - \delta$ 
  >
  > - **定义12.5 不可知 PAC 可学习**： 令 m 表示从分布 $D$ 中独立同分布采样得到的样例数目 $0 < \epsilon,\delta < 1$，对所有分布 $D$，若存在学习算法 $\xi$ 和多项式函数 $poly(.,.,.)$，使得对于任何 $m \geq poly(\frac{1}{\xi}, \frac{1}{\delta}, size(x), size(c))$，$\xi$ 能从假设空间 $H$ 中输出满足式 $P(E(h) - min_{h' \in H}E(h') \leq \epsilon) \geq 1 - \delta$，则称假设空间 $H$ 是不可知 PAC 可学习

## 4、VC 维

- **增长函数**： 对所有 $m \in N$，假设空间 $H$ 增长函数为 $\prod_H(m) = max_{\{x_1,...,x_m\} \in \chi} |\{ (h(x_1),...,h(x_m)) | h \in H \}|$ 

  > - 增长函数 $\prod_H(m)$ 表示假设空间 H 对 m 个示例所能赋予标记的最大可能结果数
  > - 增长函数 $\prod_H(m)$ 描述了假设空间 H 的表示能力

- **定理 12.2**： 对假设空间 H，$m \in N, 0 < \epsilon < 1$ 和任意 $h \in H$ 有 $P(|E(h) - \hat{E}(h)| > \epsilon) \leq 4 \prod_H(2m)exp(-\frac{m \epsilon^2}{8}) $ 

  > - **对分**： 对二分类问题来说，$H$ 中的假设对 D 中示例赋予标记的每种可能结果，称为对 D 的一种“对分”
  > - **打散**： 若假设空间 $H$ 能实现示例集 D 上的所有对分，即 $\prod_H(m) = 2^m$，则称示例集 D 能被假设空间 $H$ “打散”

- **VC 维**： 假设空间 $H$ 的 VC 维是能被 H 打散的最大示例集的大小，即 $VC(H) = max\{ m: \prod_H(m) = 2^m \}$ 

  > - $VC(H) = d$ 表明存在大小为 d 的示例集能被假设空间 H 打散
  > - **计算 VC 维方法**： 若存在大小为 d 的示例集能被 H 打散，但不存在任何大小为 d+1 的示例集能被 H 打散，则 H 的 VC 维是 d
  > - 注： VC 维德泛化误差界是分布无关、数据独立的，即对任何数据分布都成立

- **引理 12.2**： 若假设空间 H 的 VC 维为 d，则对任意 $m \in N$，有 $\prod_H(m) \leq \sum^d_{i=0}\begin{pmatrix}m \\i \end{pmatrix}$ 

- **推论 12.2**：若假设空间 H 的 VC 维为 d，则对任意 $m \geq d$ 有 $\prod_H(m) \leq (\frac{e m}{d})^d$ 
- **定理 12.3**： 若假设空间 H 的 VC 维为 d，则对任意 $m > d, 0 < \delta < 1$ 和 $h \in H$ 有 $P(E(h) - \hat{E}(h) \leq \sqrt{\frac{8d \ ln\frac{2em}{d} + 8 \ ln\frac{4}{\delta}}{m}}) \geq 1 - \delta$ 
- **定理 12.4**： 任何 VC 维有限的假设空间 H 都是(不可知)PAC可学习的

## 5、Rademacher 复杂度

- **Rademacher 复杂度**： 另一种刻画假设空间复杂度的途径，不同 VC 维的是，在一定程度上考虑了数据分布

  > - 函数空间 $F$ 关于 Z 的经验 Rademacher 复杂度： $\hat{R}_Z(F) = E_{\sigma}[sup_{f \in F}\frac1m\sum^m_{i=1}\sigma_if(z_i)]$ 
  > - 函数空间 $F$ 关于 $\zeta$ 上分布 D 的 Rademacher 复杂度： $R_m(F) = E_{Z \subseteq \zeta: |Z| = m}[\hat{R_Z}(F)]$ 

- **定理 12.5**： 对实值函数空间 $F: \zeta \rightarrow [0,1]$，根据分布 D 从 $\zeta$ 从独立同分布采样得到示例集 $Z = \{ z_1,...,z_m \}, z_i \in \zeta,0 < \delta < 1$，对任意 $f \in F$，以至少 $1 - \delta$ 的概率有

  ​					$E[f(z)] \leq \frac1m \sum^m_{i=1}f(z_i) + 2R_m(F) + \sqrt{\frac{ln(1/\delta)}{2m}}$ 

  ​					$E[f(z)] \leq \frac1m \sum^m_{i=1}f(z_i) + 2\hat{R_Z}(F) + 3\sqrt{\frac{ln(2/\delta)}{2m}}$ 

- **定理12.6**： 对假设空间 $H: \chi \rightarrow \{ -1,+1 \}$，根据从分布 D 从 $\chi$ 中独立同分布采样得到示例集 $D = \{ x_1,...,x_m \},x_i \in \chi, 0 < \delta < 1$，对任意 $h \in H$，以至少 $1 - \delta$ 的概率有 

  ​					$E(h) \leq \hat{E}(h) + R_m(H) + \sqrt{\frac{ln(1/\delta)}{2m}}$ 

  ​					$E(h) \leq \hat{E}(h) + \hat{R_D}(H) + 3\sqrt{\frac{ln(2/\delta)}{2m}}$  

- **定理 12.7**： 假设空间 H 的 Rademacher 复杂度 $R_m(H)$ 与增长函数 $\prod_H(m)$ 满足 $R_m(H) \leq \sqrt{\frac{2 \ ln \prod_H(m)}{m}}$，进而可得 $E(h) \leq \hat{E}(h) + \sqrt{\frac{2d\ ln\frac{em}{d}}{m}} + \sqrt{\frac{ln(1/\delta)}{2m}}$ 

## 6、稳定性

- **稳定性**： 考察算法在输入发生变化时，输出是否会随之发生较大的变化
- **关于 $\xi$ 几种损失**：损失函数 $l(\xi(x),y): \Upsilon \times \Upsilon \rightarrow R^+$ 刻画了假设 $\xi_D$ 的预测标记 $\xi_D(x)$ 与真实标记 y 之间的差别，简记为 $l(\xi_D,z)$ 
  - **泛化损失**： $l(\xi,D) = E_{x \in \chi,z = (x,y)}[l(\xi,z)]$
  - **经验损失**： $\hat{l}(\xi,D) = \frac1m\sum^m_{i=1}l(\xi_D,z_i)$ 
  - **留一损失**： $l_{loo}(\xi,D) = \frac1m \sum^m_{i=1}l(\xi_{D/i},z_i)$ 

- **均匀稳定性**： 对任何 $x \in \chi,z = (x,y)$，若学习算法 $\xi$ 满足 $|l(\xi_D,z) - l(\xi_{X/i,z})| \leq \beta,i = 1,2,...,m$，则称 $\xi$ 关于损失函数 $l$ 满足 $\beta$-均匀稳定性

- **定理 12.8**： 给定从分布 $D$ 上独立同分布采样得到的大小为 m 的示例集 D，若学习算法 $\xi$ 满足关于损失函数 $l$ 的 $\beta$-稳定性，且损失函数 $l$ 的上界为 M，$0 < \delta < 1$，则对任意 $m \geq 1$，以至少 $1 - \delta$ 的概率有 

  ​								$l(\xi,D) \leq \hat{l}(\xi,D) + 2 \beta + (4m\beta + M)\sqrt{\frac{ln(1/\delta)}{2m}} $

  ​								$l(\xi,D) \leq l_{loo}(\xi,D) + \beta + (4m\beta + M)\sqrt{\frac{ln(1/\delta)}{2m}} $ 

- **定理 12.9**： 若学习算法 $\xi$ 是 ERM 且稳定的，则假设空间 H 可学习

  > **ERM(经验风险最小化)算法**： 对损失函数 $l$，学习算法 $\xi$ 所输出的假设满足经验损失最小化

# 第十三章：半监督学习

## 1、未标记样本

- **主动学习**： 使用尽量少的“查询”来获得尽量好的性能

- **半监督学习**： 让学习器不依赖外界交互、自动地利用未标记样本来提升学习性能

  > 要利用未标记样本，要将未标记样本所揭示的数据分布信息与类别标记相联系的假设

- 半监督学习的常见假设： 
  - **聚类假设**： 用于处理未标记样本，即假设数据存在簇结构，同一个簇的样本属于同一个类别
  - **流行假设**： 假设数据分布在一个流行结构上，邻近的样本拥有相似的输出值

- 半监督学习的划分： 

  - **纯半监督学习**： 假定训练数据中的未标记样本并非待预测的数据

    > - 基于“开放世界”假设，希望学的模型能适用于训练过程中未观察到的数据

  - **直推学习**： 假定学习过程中所考虑的未标记样本恰是待预测数据，学习的目的在未标记样本上获得最优泛化性能

    > - 基于“封闭世界”假设，仅试图对学习过程中观察到的未标记数据进行预测

  ![](../pics/machine/machine_48.png)

## 2、生成式方法

- **生成式方法**： 直接基于生成式模型的方法，假设所有数据(无论是否有标记)都是由同一个潜在的模型“生成”

  > - 该假设可使我们通过潜在模型的参数将未标记数据与学习目标联系起来，而未标记数据的标记则可看作模型的缺失参数，可基于 EM 算法进行极大似然估计求解
  > - 此类方法的却别： 在于生成式模型的假设，不同的模型将产生不同的方法

- 假设样本由高斯模型生成，且每个类别对应一个高斯混合成分： 

  > - 数据样本的概率密度： $p(x) = \sum^N_{i=1}a_i \ p(x|\mu_i,\sum_i)$ 
  >
  >   > - 混合系数 $a_i \geq 0,\sum^N_{i=1}a_i = 1$
  >   > - $p(x|\mu_i,\sum_i)$ 是样本 x 属于第 $i$ 个高斯混合成分的概率
  >   > - $\mu_i$ 和 $\sum_i$ 为该高斯混合成分的参数
  >
  > - 最大化后验概率： $f(x) = arg_{j \in \Upsilon} max \sum^N_{i=1}p(y = j, \Theta = i|x) \ p(\Theta = i|x)$ 
  >
  >   > - 其中 $p(\theta = i | x) = \frac{a_i \ p(x|\mu_i,\sum_i)}{\sum^N_{i=1}a_i \ p(x|\mu_i,\sum_i)}$ 
  >
  > - $D_l \bigcup D_u$ 的对数似然： $LL(D_l \bigcup D_u) = \sum_{(x_j,y_j) \in D_l}ln(\sum^N_{i=1}a_i \ p(x_j|\mu_i,\sum_i) \ p(y_j|\theta = i,x_j)) + \sum_{x_j \in D_u} ln(\sum^N_{i=1}a_i \ p(x_j|\mu_i,\sum_i))$
  >
  >   > - 上式基于有标记数据 $D_l$ 的有监督项和未标记数据 $D_u$ 的无监督项
  >   >
  >   > - 上式的高斯混合模型参数估计可用 EM 算法求解，迭代更新式： 
  >   >
  >   >   - **E 步**： 根据当前模型参数计算未标记样本 $x_j$ 属于各高斯混合成分的概率：$\gamma_{ji} = \frac{a_i \ p(x_j|\mu_i,\sum_i)}{\sum^N_{i=1}a_i \ p(x_j|\mu_i,\sum_i)}$ 
  >   >
  >   >   - **M 步**： 基于 $\gamma_{ji}$ 更新模型参数，其中 $l_i$ 表示第 $i$ 类的有标记样本数目
  >   >
  >   >     $\mu_i = \frac{1}{\sum_{x_j \in D_u}\gamma_{ji} + l_i}(\sum_{x_j \in D_u}\gamma_{ji}x_j + \sum_{(x_j,y_j) \in D_l \bigwedge y_j = i}x_j)$ 
  >   >
  >   >     $\sum_i = \frac{1}{\sum_{x_j \in D_u}\gamma_{ji} + l_i}(\sum_{x_j \in D_u}\gamma_{ji}(x_j - \mu_i)(x_j - \mu_i)^T + \sum_{(x_j,y_j) \in D_l \bigwedge y_j = i}(x_j - \mu_i)(x_j - \mu_i)^T)$ $a_i = \frac1m (\sum_{x_J \in D_u}\gamma_{ji} + l_i)$ 

## 3、半监督 SVM

- **半监督支持向量机(S3VM)**： 在考虑未标记样本后，S3VM 试图找到能将两类有标记样本分开，且穿过数据低密度区域的划分超平面

  ![](../pics/machine/machine_49.png)

- **TSVM**： 针对二分类问题，TSVM 试图考虑对未标记样本进行各种可能的标记指派，即尝试将每个未标记样本分别作为正例或反例，然后再所有这些结果中，寻求一个在所有样本上间隔最大化的划分超平面

  > - 一旦划分超平面确定，未标记样本的最终标记指派就是其预测结果
  > - TSVM 采用局部搜索来迭代寻找式 $min_{w,b,\overline{y},\xi} \ \frac12 ||w||^2_2 + C_l \sum^l_{i=1}\xi_i + C_u \sum^m_{i = l+1}\xi_i$ 近似解
  >
  > ![](../pics/machine/machine_50.png)

## 4、图半监督学习

- **数据集映射为图**： 数据集中每个样本对应于图中的一个结点，若两个样本间的相似度很高，则对应的结点之间存在一条边，边的“强度”正比于样本之间的相似度

  > - 将有标记样本所对应的结点想象为染过色
  > - 未标记样本所对应的结点尚未染色

- **图半监督学习**： 对应于“颜色”在图上扩散或传播的过程

- **构建图**： 给定 $D_l = \{ (x_1,y_1),...,(x_l,y_l) \}$ 和 $D_u = \{ x_{l+1},...,x_{l+u} \}, \ l << u, l + u = m$，基于 $D_l \bigcup D_u$ 构建图 $G = (V,E)$ 

  > - 结点集：$V = \{ x_1,...,x_l,x_{l+1},...,x_{l+u} \}$
  >
  > - 边集 E 可表示为一个亲和矩阵，常基于高斯函数定义： $(W)_{ij} = $$\begin{cases} exp(\frac{-||x_i - x_j||^2_2}{2 \sigma^2}, \ \ if \ i \neq j \\ 0, \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ otherwise \end{cases} $ 
  >
  >   > 其中 $i,j \in \{ 1,2,...,m \},\sigma > 0$ 是用户指定的高斯函数带宽参数
  >   >
  >   > ![](../pics/machine/machine_51.png)
  >   >
  >   > ==详细推导，后续慢慢研究==

## 5、基于分歧的方法

- **基于分歧的方法**： 使用多学习器，而学习器之间的“分歧”对未标记数据的利用至关重要

- **协同训练**： 基于分歧方法和多视图学习的代表

  ![](../pics/machine/machine_52.png)

## 6、半监督聚类

- 聚类任务获得监督信息的两种类型：

  - **必连**： 指样本必属于同一个簇

    > **约束 k 均值算法**： 
    >
    > ![](../pics/machine/machine_53.png)

  - **勿连**： 指样本必不属于同一个簇，监督信息是少量油标记样本

    > **约束种子 k 均值**： 
    >
    > ![](../pics/machine/machine_54.png)

# 第十四章：概率图模型

## 1、隐马尔可夫模型

- **生成式模型**： 对**联合分布**进行建模
- **判别式模型**： 对**条件分布**进行建模

---

- **概率模型**： 提供一种描述框架，将学习任务归结于计算变量的概率分布
- **概率图模型**： 用图来表达变量相关关系的概率模型，一个结点表示一个或一组随机变量，结点之间的边表示变量间的概率相关关系
  - 第一类： **有向图模型或贝叶斯网**，即使用有向无环图表示变量间的依赖关系
  - 第二类： **无向图模型或马尔可夫网**，即使用无向图表示变量间的相关关系

- **隐马尔可夫模型(HMM)**：动态贝叶斯网，有向图模型，用于**时序数据建模**，如：语音识别、自然语言处理

  > HMM 的变量分为两组： 
  >
  > - 第一组：**状态变量** $\{ y_1,...,y_n \}$，其中 $y_i \in \Upsilon$ 表示第 $i$ 时刻的系统状态
  >
  >   > 通常假定状态变量是隐藏的、不可被观测的，因此状态变量亦称隐变量
  >
  > - 第二组： **观测变量** $\{ x_1,...,x_n \}$，其中 $x_i \in \chi$ 表示第 $i$ 时刻的观测值
  >
  > ![](../pics/machine/machine_55.png)
  >
  > - 上图中的箭头表示变量间的依赖关系，观测变量的取值仅依赖于状态变量，即 $x_t$ 由 $y_t$ 确定
  >
  > - **马尔可夫链**： 系统下一时刻的状态仅由当前状态决定，不依赖于以往的任何状态，即 $y_t$ 仅依赖 $y_{t-1}$ 
  >
  >   > 基于这种依赖关系，所有变量的联合概率分布： $P(x_1,y_1,...,x_n,y_n) = P(y_1)P(x_1|y_1)\prod^n_{i=2}P(y_i|y_{i-1})P(x_i|y_i)$ 
  >
  > **确定隐马尔可夫模型的三组参数**： 
  >
  > - **状态转移概率**： 模型在各个状态间转换的概率，记为矩阵 $A = [a_{ij}]_{N \times N}$
  >
  >   > 其中 $a_{ij} = P(y_{t+1} = s_j|y_t = s_i), \ \ 1 \leq i,j \leq N $ 表示在任意时刻 t，若状态为 $s_i$，则在下一时刻状态为 $s_j$ 的概率
  >
  > - **输出观测概率**： 模型根据当前状态获得各个观测值的概率，记为矩阵 $B = [b_{ij}]_{N \times N}$ 
  >
  >   > 其中 $b_{ij} = P(x_t = o_j | y_t = s_i), \ \ 1 \leq i \leq N, \ 1 \leq j \leq M $ 表示在任意时刻 t，若状态为 $s_i$，则观测值 $o_j$ 被获取的概率
  >
  > - **初始状态概率**：模型在初始时刻各状态出现的概率，记为 $\pi = (\pi_1,...,\pi_N)$
  >
  >   > 其中 $\pi_i = P(y_1 = s_i), \ \ 1 \leq i \leq N $ 表示模型的初始状态为 $s_i$ 的概率
  >
  > ---
  >
  > 通过指定状态空间 $\Upsilon$、观测空间 $\chi$ 和上述三组参数，就能确定隐马尔可夫模型，用 $\lambda = [A,B,\pi]$ 来指代

- 给定隐马尔可夫模型 $\lambda$，按如下过程**产生观测序列** $\{ x_1,...,x_n \}$：

  1. 设置 t=1，并根据初始状态概率 $\pi$ 选择初始状态 $y_1$
  2. 根据状态 $y_t$ 和输出观测概率 B 选择观测变量取值 $x_t$ 
  3. 根据状态 $y_t$ 和状态转移矩阵 A 转移模型状态，即确定 $y_{t+1}$ 
  4. 若 t < n，设置 t = t+1，并转到第 2 步，否则停止

  > 其中 $y_t \in \{ s_1,...,s_N \}$ 和 $x_t \in \{ o_1,...,o_M \}$ 分别为第 t 时刻的状态和观测值

- 隐马尔可夫模型的**三个基本问题**： 

  - 给定模型 $\lambda = [A,B,\pi]$，如何**有效计算其产生观测序列** $x = \{ x_1,...,x_n \}$ 的概率 $P(x|\lambda)$？

    > 即如何评估模型与观测序列之间的匹配程度?

  - 给定模型 $\lambda = [A,B,\pi]$ 和观测序列 $x = \{ x_1,...,x_n \}$，如何**找到与此观测序列最匹配的状态序列** $y = \{ y_1,...,y_n \}$？

    > 即如何根据观测序列推断出隐藏的模型状态？

  - 给定观测序列 $x = \{ x_1,...,x_n \}$，如何调整模型参数 $\lambda = [A,B,\pi]$ **使该序列出现的概率 $P(x|\lambda)$ 最大**？

    > 即如何训练模型使其最好的描述观测数据？

## 2、马尔可夫随机机场

- **马尔可夫随机场(MRF)**： 典型的马尔可夫网，无向图模型，途中每个结点表示一个或一组变量，结点之间的边表示两个变量之间的依赖关系

  > - 有一组势函数，亦称“因子”，这是定义在变量子集上的非负函数，用于定义概率分布函数
  >
  > ![](../pics/machine/machine_56.png)
  >
  > - 若任意两结点间有边连接，则称该结点子集为一个“团”
  > - 若在一个团中加入另外任何一个结点都不再形成团，则称该团为“极大团”

- **全局马尔可夫性**： 给定两个变量子集的分离集，则这两个变量子集条件独立

  > ![](../pics/machine/machine_57.png)
  >
  > 由全局马尔可夫性得到的两个推论： 
  >
  > - **局部马尔可夫性**： 给定某变量的邻接变量，则该变量条件独立于其他变量
  >
  >   > 即 V 为图结点集，n(v) 为 v 在图上的邻接结点，$n^*(v) = n(v) \cup \{v\}$，有 $x_v \bot x_{V/n^*(v)}|x_n(v)$ 
  >
  > - **成对马尔可夫性**： 给定所有其他变量，两个非邻接变量条件独立
  >
  >   > 即 V 和 E 为图的结点集和边集，对结点 u 和 v，若 $(u,v) \notin E$，则 $x_u \bot x_v | x_{V/(u,v)}$

## 3、条件随机场

- **条件随机场(CRF)**：判别式模型，用于判别无向图模型，试图对多个变量在给定观测值后的条件概率进行建模

- **链式条件随机场**： 最常用

  > ![](../pics/machine/machine_58.png)

## 4、学习与推断

- **边际分布**： 对无关变量求和或积分后得到结果
- **边际化**： 对联合分布中其他无关变量进行积分的过程

- 概率图模型的推断方法分为两类：

  - 第一类： **精确推断方法**，计算出目标变量的边际分布或条件分布的精确值
  - 第二类： **近似推断方法**，在较低的时间复杂度下获得原问题的近似解

- 两种代表性的精确推断方法：

  - **变量消去**：类似动态规划，利用图模型所描述的条件独立性来消减计算目标概率所需的计算量，是构建其他精确推断算法的基础

    > 工作流程： 
    >
    > ![](../pics/machine/machine_59.png)
    >
    > 1. 假定推断目标是计算边际概率 $P(x_5)$，则通过加法消去变量 $\{ x_1,x_2,x_3,x_4 \}$，即 $P(x_5) = \sum_{x_4}\sum_{x_3}\sum_{x_2}\sum_{x_1}P(x_1,x_2,x_3,x_4,x_5) = \sum_{x_4}\sum_{x_3}\sum_{x_2}\sum_{x_1}P(x_1)P(x_2|x_1)P(x_3|x_2)P(x_4|x_3)P(x_5|x_3)$
    >
    > 2. 采用顺序计算加法： $P(x_5) = \sum_{x_3}P(x_5|x_3)\sum_{x_4}P(x_4|x_3)\sum_{x_2}P(x_3|x_2)m_{12}(x_2)$ 
    >
    >    > $m_{ij}(x_j)$ 是求加过程的中间结果，下标 $i$ 表示此项是对 $x_i$ 求加的结果，下标 $j$ 表示此项中剩下的其他变量
    >
    > 3. 不断执行，得到 $P(x_5) = \sum_{x_3}P(x_5|x_3)\sum_{x_4}P(x_4|x_3)m_{23}(x_3) = m_{35}(x_5)$ 

  - **信念传播**： 将变量消去法中的求和操作看作一个消息传递过程，解决了求解多个边际分布时的重复计算问题

    > - 变量消去法的求和操作： $m_{ij}(x_j) = \sum_{x_i}\psi(x_i,x_j)\prod_{k \in n(i)/j}m_{ki}(x_i)$ 
    > - 信念传播算法中，一个结点仅在收到来自其他所有结点的消息后才能向另一个结点发送消息，且结点的边际分布正比于它所接收的消息的乘积： $P(x_i) \propto \prod_{k \in n(i)} m_{ki}(x_i)$ 
    >
    > ---
    >
    > **信念传播算法的步骤**： 若图没有环，则经过下述两个步骤即可完成所有消息传递，进而计算所有变量上的边际分布
    >
    > - 指定一个根结点，从所有叶结点开始向根节点传递信息，直到根结点收到所有邻接结点的消息
    > - 从根结点开始向叶结点传递消息，直到所有叶结点均受到消息
    >
    > ![](../pics/machine/machine_60.png)

## 5、近似推断

- **马尔可夫链蒙特卡罗(MCMC)采样**： 构造”平稳分布为 p 的马尔可夫链“来产生样本

  > - 若马尔可夫链运行时间足够长(即收敛到平稳状态)，则产生的样本 x 近似服从于分布 p
  >
  > - 马尔可夫链收敛到平稳状态： $p(x^t)T(x^{t-1}|x^t) = p(x^{t-1})T(x^t|x^{t-1})$ 
  >
  >   > $T(x'|x)$ 为平稳马尔可夫链 T 的状态转移概率，$p(x^t)$ 为 t 时刻状态的分布
  >
  > ---
  >
  > **MH 算法**： 基于”拒绝采样“来逼近平稳分布 p
  >
  > - 为达到平稳状态，将接受率设置为 $A(x^*|x^{t-1}) = min(1,\frac{p(x^*)Q(x^{t-1}|x^*)}{p(x^{t-1})Q(x^*|x^{t-1})}) \ \ \ (14.28)$ 
  >
  > ![](../pics/machine/machine_61.png)
  >
  > ---
  >
  > **吉布斯采样**： MH 算法的特例，也是用马尔可夫链获取样本
  >
  > 循环执行以下步骤来完成采样： 
  >
  > 1. 随机或以某个次序选取某变量 $x_i$
  >
  > 2. 根据 x 中除 $x_i$ 外的变量的现有取值，计算条件概率 $p(x_i|x_{\overline{i}})$ 
  >
  >    > 其中 $x_{\overline{i}} = \{ x_1,x_2,...,x_{i-1},x_{i+1},...,x_N \}$ 
  >
  > 3. 根据 $p(x_i|x_{\overline{i}})$ 对变量 $x_i$ 采样，用采样值代替原值

- **盘式记法**： 概率图模型的一种简洁表示方法

  > - 相互独立的、由相同机制生成的多个变量被放在一个方框内，并在方框中标出类似变量重复出现的个数 N，方框可以嵌套
  > - 用阴影标注出已知的、能观察到的变量
  >
  > ![](../pics/machine/machine_62.png)

- **变分推断**： 通过使用已知简单分布来逼近需推断的复杂分布，并通过限制近似分布的类型，从而得到一种局部最优、但具有确定解的近似后验分布

## 6、话题模型

- **话题模型**： 生成式有向图模型，用于处理离散型的数据(如文本集合)

- 话题模型的几个概念：

  - **词**： 待处理数据的基本离散单元
  - **文档**： 待处理的数据对象，由一组词组成
  - **话题**： 表示一个概念，具体表示为一系列相关的此，以及它们在该概念下出现的概率

- **隐迪利克雷分配模型(LDA)**： 话题模型的典型代表，从生成式模型的角度来看待文档和话题

  > 通过下面的步骤由话题”生成“文档 t：
  >
  > - 根据参数为 $\alpha$ 的狄利克雷分布随机采样一个话题分布 $\Theta_t$
  >
  > - 按如下步骤生成文档中的 N 个词：
  >
  >   1. 根据 $\Theta_t$ 进行话题指派，得到文档 t 中词 n 的话题 $z_{t,n}$ 
  >   2. 根据指派的话题所对应的词频分布 $\beta_k$ 随机采样生成词
  >
  >   ![](../pics/machine/machine_63.png)

# 第十五章：规则学习

## 1、基本概念

- **规则学习**： 从训练数据中学习出一组能用于对未见示例进行判别的规则

- 表示： $\oplus \leftarrow f_1 \wedge f_2 \wedge ... \wedge f_L$

  > - $f_1 \wedge f_2 \wedge ... \wedge f_L$ 称为规则体，表示该条规则的前提
  > - $\oplus$ 称为规则头，表示该条规则的结果

- 目标： 产生一个能覆盖尽可能多的样例的规则集

## 2、序贯覆盖

- **序贯覆盖**： 即逐条归纳，在训练集上每学到一条规则，就将该规则覆盖的训练样例去除，然后以剩下的训练样例组成训练集重复上述过程

  > 由于每次只处理一部分数据，也称为”分治策略“

## 3、剪枝优化

- **剪枝**： 缓解规则生成时的过拟合风险

  > 通常是基于某种性能度量指标来评估增/删逻辑文字前后的规则性能，或增/删规则前后的规则集性能，从而判断是否要进行剪枝

- **预剪枝**： 发生在规则生长过程中

  > - **CN2 算法**： 借助统计显著性校验来进行剪枝，即在预剪枝时，假设用规则集进行预测必须显著优于直接基于训练样例集后验概率分布进行预测
  >
  >   CN2 使用了**似然率统计量(LRS)**：令 $m_+, m_{-}$  表示训练样例集中的正、反例数目， $\hat{m_+}, \hat{m_-}$ 表示规则(集)覆盖的正、反例数目，则有  $LRS = 2 (\hat{m_+} log_2\frac{\frac{\hat{m_+}}{\hat{m_+} + \hat{m_-}}}{\frac{m_+}{m_+ + m_-}} + \hat{m_-}log_2 \frac{\frac{\hat{m_-}}{\hat{m_+} + \hat{m_-}}}{\frac{m_-}{m_+ + m_-}})$ 
  >
  >   - LRS 越大，说明采用规则(集)进行预测与直接使用训练集正、反例比率进行猜测的差别越大
  >   - LRS 越小，说明规则(集)的效果越可能仅是偶然现象
  >
  >   > 通常设置为在 LRS 很大(如：0.99)时，CN2算法才停止规则(集)生长

- **后剪枝**： 发生在规则产生后

  > - **减错剪枝(REP)**： 复杂度 $O(m^4)$，m 为训练样例数目，**对规则集进行剪枝**
  >   - 将样例集划分为训练集和验证集，从训练集上学得规则集 R 后进行多轮剪枝，在每一轮穷举所有可能的剪枝操作
  >   - 然后用验证集对剪枝产生的候选规则集进行评估，保留最好的规则集进行下一轮剪枝
  >   - 如此继续，直到无法通过剪枝提高验证集上的性能为止
  > - IREP： 将复杂度降到 $O(m log^2m)$，**仅对单条规则进行剪枝**
  >   - 在生成每条规则前，先将当前样例集划分为训练集和验证集
  >   - 在训练集上生成一条规则 r，立即在验证集上对其进行 REP 剪枝，得到规则 $r'$ 
  >   - 将 $r'$ 覆盖的样例去除，在更新后的样例集上重复上述过程

- **RIPPER 算法**： 规则学习算法

  > - 先使用 $IREP^*$ 剪枝机制生成规则集 R
  >
  >   > $IREP^*$ 是 IREP 的改进，以 $\frac{\hat{m_+} + (m_- - \hat{m_-})}{m_+ + m_-}$ 取代 IREP 使用的准确率作为规则性能度量指标
  >   >
  >   > - 在剪枝时删除尾部的多个文字，并在最终得到规则集后再进行一次 IREP 剪枝
  >
  > ![](../pics/machine/machine_64.png)

## 4、一阶规则学习

- 命题规则学习或一般统计学习中，引入领域知识的两种做法： 

  - 做法一： 在现有属性的基础上，基于领域知识构造出新属性
  - 做法二： 基于领域知识设计某种函数机制(如正则化)来对假设空间加以约束

- **一阶规则学习**： 能容易地引入领域知识

- **FOIL 算法**： 著名的一阶规则学习算法，遵循序贯覆盖框架且采用自顶向下的规则归纳策略

  > - FOIL 增益： $F_Gain = \hat{m_+} \times (log_2 \frac{\hat{m_+}}{\hat{m_+} + \hat{m_-}} - log_2 \frac{m_+}{m_+ + m_-})$ 
  >
  >   > $\hat{m_+}, \hat{m_-}$ 为增加候选文字后新规则所覆盖的正、反例数，$m_+, m_-$ 为原规则覆盖的正、反例数

## 5、归纳逻辑程序设计

- **归纳逻辑程序设计(ILP)**：在一阶规则学习中引入函数和逻辑表达式嵌套，即采用自底向上的规则生成策略，直接将一个或多个正例所对应的具体事实作为初始规则，再对规则逐步进行泛化以增加其对样例的覆盖率

  > 泛化操作可以将规则中的常量替换为逻辑变量，也可以是删除规则体中的某个文字

  - 一方面，使得机器学习系统具备了更为强大的表达能力
  - 另一方面，ILP 可看作用机器学习技术来解决基于背景知识的逻辑程序归纳，其学得的”规则“可被 PROLOG 等逻辑程序设计语言直接使用

- **最小一般泛化(LGG)**： 

  > 过程： 
  >
  > - 给定一阶公式 $r_1$ 和 $r_2$，LGG 先找出涉及相同谓词的文字，然后对文字中每个位置的常量逐一进行考察
  >
  > - 若常量在两个文字中相同则保持不变，记为 $LGG(t,t) = t$
  >
  > - 否则将它们替换为同一个新变量，并将该变量替换应用公式的所有其他位置
  >
  >   > 假定这两个不同的常量分别为 s,t，新变量为 V，则记为 $LGG(s,t) = V$，并在以后所有出现 $LGG(s,t)$ 的位置用 V 来代替

- **逆归纳**： 

  > - 演绎： 从一般性规律出发来探讨具体事物
  >
  > - 归纳： 从个别事物出发概括出一般性规律
  >
  >   > 机器学习属于归纳的范畴
  >
  > - 置换： 用某些项来替换表达式中的变量
  >
  > - 合一： 用一种变量置换令两个或多个逻辑表达式相等

# 第十六章：强化学习

## 1、任务与奖赏

- **强化学习**： 在多次的学习过程中，不断摸索，总结出较好的学习策略

  > 强化学习通常用马尔可夫决策过程(MDP)来描述
  >
  > ![](../pics/machine/machine_65.png)

- **马尔可夫决策过程(MDP)**： 强化学习任务对应四元组 $E = <X,A,P,R>$

  > 其中 $P: X \times A \times X \rightarrow R$ 指定了状态转移概率，$R: X \times A \times X \rightarrow R$ 指定了奖赏，奖赏函数可能仅余状态转移有关，即 $R: X \times X \rightarrow R$ 

  - 机器处于环境 E 中，状态空间为 X，其中每个状态 $x \in X$ 是机器感知到的环境的描述
  - 机器能采取的动作构成了动作空间 A
  - 若某个动作 $a \in A$ 作用在当前状态 x 上，则潜在的转移函数 P 将使得环境从当前状态按某种概率转移到另一个状态
  - 在转移到另一个状态的同时，环境会根据潜在的”奖赏“函数 R 反馈给机器一个奖赏

## 2、K-摇臂赌博机

- **探索与利用**： 通过一定策略**最大化奖赏**

  > - 若仅为获知**每个摇臂的期望奖赏**，则采用**”仅探索“法**： 将所有的尝试机会平均分配给每个摇臂(即轮流按下每个摇臂)，最后以每个摇臂各自的平均吐币概率作为其奖赏期望的近似估计
  >
  >   > **仅探索法**能很好地估计每个摇臂的奖赏，却会失去很多选择最优摇臂的机会
  >
  > - 若仅为执行**奖赏最大**的动作，则采用**”仅利用“法**： 按下目前最优的(即到目前为止平均奖赏最大)摇臂，若有多个摇臂同为最优，则从中随机选取一个
  >
  >   > **仅利用法**没有很好的估计摇臂期望奖赏，很可能选不到最优摇臂
  >
  > ![](../pics/machine/machine_66.png)

- **$\epsilon$-贪心**： 基于一个概率来对探索和利用进行折中

  > - 每次尝试时，以 $\epsilon$ 的概率进行探索，即以均匀概率随机选取一个摇臂
  > - 以 $1 - \epsilon$ 的概率进行利用，即选择当前平均奖赏最高的摇臂(若有多个，随机选取一个)
  >
  > ![](../pics/machine/machine_67.png)

- **Softmax**： 基于当前已知的摇臂平均奖赏来对探索和利用进行折中

  > - 若各摇臂的平均奖赏相当，则选取各摇臂的概率也相当；若某些摇臂的平均奖赏高于其他摇臂，则它们被选取的概率也更高
  > - Softmax 的概率分配基于 **Boltzmann 分布**： $p(k) = \frac{e^{\frac{Q(k)}{\tau}}}{\sum^K_{i=1}e^{\frac{Q(i)}{\tau}}}$ 
  >
  > ![](../pics/machine/machine_68.png)

## 3、有模型学习

- **有模型学习**： 在已知模型的环境中学习

- **策略评估**： 在模型已知时，对任意策略 $\pi$ 能估计出该策略带来的期望累积奖赏

  > - 函数 $V^{\pi}(x)$ 表示从状态 x 出发，使用策略 $\pi$ 所带来的累积奖赏
  >
  >   > 状态值函数： $\begin{cases} V^{\pi}_T(x) = E_{\pi}[\frac1T\sum^{T}_{t=1}r_t | x_0 = x], \ \ T 步累积奖赏 \\  V^{\pi}_{\gamma}(x) = E_{\pi}[\frac1T\sum^{+\infty}_{t=0}\gamma^tr_{t+1} | x_0 = x], \ \ \gamma 折扣累积奖赏\end{cases}$ 
  >
  > - 函数 $Q^{\pi}(x,a)$ 表示从状态 x 出发，执行动作 a 后再使用策略 $\pi$ 带来的累积奖赏
  >
  >   > 状态-动作值函数： $\begin{cases} Q^{\pi}_T(x,a) = E_{\pi}[\frac1T\sum^{T}_{t=1}r_t | x_0 = x,a_0 = a] \\  Q^{\pi}_{\gamma}(x) = E_{\pi}[\frac1T\sum^{+\infty}_{t=0}\gamma^tr_{t+1} | x_0 = x,a_0 = a]\end{cases}$ 
  >
  > ![](../pics/machine/machine_69.png)

- **策略改进**： 

  > - 理想策略的最大化累积奖赏： $\pi^* = arg_{\pi} max \sum_{x \in X} V^{\pi}(x)$ 
  > - 强化学习任务可能有多个最优策略，最优策略所对应的值函数 $V^*$ 为最优值函数，即 $\forall x \in X: \ V^*(x) = V^{\pi^*}(x)$ 
  >
  > ---
  >
  > - 对动作的求和改为取最优： $\begin{cases} V^{*}_T(x) = max_{a \in A} \sum_{x' \in X}P^a_{x \rightarrow x'}(\frac1T R^a_{x \rightarrow x'} + \frac{T - 1}{T}V^*_{T - 1}(x')) \\  V^{*}_{\gamma}(x) = max_{a \in A} \sum_{x' \in X}P^a_{x \rightarrow x'}(R^a_{x \rightarrow x'} + \gamma V^*_{\gamma}(x')) \end{cases}$ 
  > - 最优状态-动作值函数： $\begin{cases} Q^{*}_T(x,a) = \sum_{x' \in X}P^a_{x \rightarrow x'}(\frac1T R^a_{x \rightarrow x'} + \frac{T - 1}{T} max_{a' \in A}Q^*_{T - 1}(x',a')) \\  Q^{*}_{\gamma}(x,a) = \sum_{x' \in X}P^a_{x \rightarrow x'}(R^a_{x \rightarrow x'} + \gamma \ max_{a' \in A} Q^*_{\gamma}(x',a')) \end{cases}$ 

- **策略迭代与值迭代**： 

  > - 策略迭代： 
  >
  > ![](../pics/machine/machine_70.png)
  >
  > - 值迭代： 
  >
  > ![](../pics/machine/machine_71.png)

## 4、免模型学习

- **免模型学习**： 学习算法不依赖于环境建模

常见算法：

- **蒙特卡罗强化学习**： 又称 T 步累积奖赏的强化学习任务，即多次采样，然后求取平均累积奖赏来作为期望累积奖赏的近似

  > - 免模型情形下，策略迭代算法的问题： 策略无法评估，是因为模型未知而导致无法做全概率展开
  > - 本质： 通过多次尝试后，求平均来作为期望累积奖赏的近似
  > - 优点： 通过考虑采样轨迹，克服了模型未知给策略估计造成的困难
  > - 局限： 没有充分利用强化学习任务的 MDP 结构
  >
  > ![](../pics/machine/machine_72.png)
  >
  > ![](../pics/machine/machine_73.png)

- **时序差分(TD)学习**： 结合了动态规划和蒙特卡罗方法的思想

  > 式 (16.31)：$Q^{\pi}_{t+1}(x,a) = Q^{\pi}_{t}(x,a) + a (R^a_{x \rightarrow x'} + \gamma \ Q^{\pi}_t(x',a') - Q^{\pi}_t(x,a))$ 
  >
  > - Sarsa 算法： 
  >
  >   ![](../pics/machine/machine_74.png)
  >
  > - Q-学习算法： 将 Sarsa 修改为异策略算法
  >
  >   ![](../pics/machine/machine_75.png)

## 5、值函数近似

- **值函数**： 指关于有限状态的”表格值函数“，即值函数能表示为一个数组，输入 i 对应的函数值就是数组元素 i 的值，且更改一个状态上的值不会影响其他状态上的值

- **值函数近似**： 无法像有限状态那样精确记录每个状态的值的值函数的求解

  > 基于线性值函数近似来替代 Sarsa 算法中的值函数： 
  >
  > 式 (16.36)：$\theta = \theta + a(r + \gamma \ \theta^T x' - \theta^T x)x$ 
  >
  > ![](../pics/machine/machine_76.png)

## 6、模仿学习

- **直接模仿学习**： 直接模仿人类专家的”状态-动作对“

- **逆强化学习**： 从人类专家提供的范例数据中反推出奖赏函数

  > ![](../pics/machine/machine_77.png)